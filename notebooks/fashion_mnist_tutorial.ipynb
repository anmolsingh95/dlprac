{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "342e0815-5846-4a3a-8008-9cab609c655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63c5246c-9a03-4fd1-ab94-1f5bdc06befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tensor(tensor):\n",
    "    image_numpy = tensor[0].squeeze().numpy()\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.imshow(image_numpy, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541396da-9d28-4d75-995e-6fbebbf79f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(\"../data\", train=True, download=True)\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(train_data[2][0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956f674b-f64c-45f2-9670-bba68c217382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHv0lEQVR4nO3dv2pUaxvG4ZWtyQSNGsX/2ggilp6CJ2BrJXgEFnbiadgLtmJhY2NhLwjWNpJCCBjRiMTEJOYrLHbxwfu8w5qoO/d1tU+yZmW2v72KZ82aub29vb0BOND++dMnAOw/oUMAoUMAoUMAoUMAoUMAoUMAoUMAoUOAw70/ODc3t5/ncWCcPXu2Ob979255jCdPnjTnq6ur05zSH3Hjxo3m/Pr16+Uxnj171pxvb29Pc0oHVs/Nra7oEEDoEEDoEEDoEEDoEEDoEEDoEKB7j84vS0tLzfmtW7ea8zt37pSvcfv27eZ8bW2tOf/x48eo+TAMw7Fjx5rzyWTSnF++fLk5f/78eXkOu7u7zfnTp0/LY/CLKzoEEDoEEDoEEDoEEDoEEDoEEDoEsEef0rdv35rz9fX15vzBgwflazx8+LA5rz7Lfe7cuea82oEPwzB8/vy5Oa/eh5cvXzbnL168KM+humeBfq7oEEDoEEDoEEDoEEDoEEDoEEDoEEDoEMANMzO2sLDQnH/58qU8xqNHj5rze/fuNedbW1vNec8NM9V5vnnzpjl//Phxc37lypXyHD5+/Fj+DH1c0SGA0CGA0CGA0CGA0CGA0CGA0CGAPfqMVQ9kOH36dHmMlZWV5vz+/fvNefXlCWfOnCnP4f379835p0+fmvPq7zx8uP6nNzc3V/4MfVzRIYDQIYDQIYDQIYDQIYDQIYDQIYA9+ozt7OyMPkbPrr1lbW2tOV9dXS2PceTIkeb80qVLzfnu7m5zvre3V55Dz8/QxxUdAggdAggdAggdAggdAggdAggdAtijz9g//7T/39mzG6520IcOHWrOl5eXy9fYb9VnyXveh57PrNPHFR0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CuCNhxpaWlprzyWRSHmNzc7M5r26Y+fnz56jfH4bxX55Q3ThUzYdhGBYXF0edA/9yRYcAQocAQocAQocAQocAQocAQocA9ugzVj0soWc/Xf1MtYOufr/nHMa+RvVFFj179J59P31c0SGA0CGA0CGA0CGA0CGA0CGA0CGAPfqMVfvhjY2N8hjV/njsjrv6gogePV/A0LK1tTX6HOjnig4BhA4BhA4BhA4BhA4BhA4BhA4B7NFnrOdz1pX9fm77LM6xUn0uv2ePfvbs2VmdTjxXdAggdAggdAggdAggdAggdAggdAggdAjghpkpnTx5sjmvblbp+fKE6qEOv+OGl0p10051w8zm5mb5GkePHm3OFxcXR79Gij//LwbYd0KHAEKHAEKHAEKHAEKHAEKHAPboU6oemFDNx37xQY9ZvEa17x+7y6/uNxiGYVhfX2/O7cn7uaJDAKFDAKFDAKFDAKFDAKFDAKFDAHv0KVU76p79cILqfZpMJr/pTBgGV3SIIHQIIHQIIHQIIHQIIHQIIHQIYI8+pbF78up56MOw/89t/xvOoef4u7u7o47R83emcEWHAEKHAEKHAEKHAEKHAEKHAEKHAEKHAG6YmdLi4mJzXj1woefLFaovTxh7I8nveDhG9Tf0vA/VzywsLDTnvuDhX67oEEDoEEDoEEDoEEDoEEDoEEDoEMAefUrVfnjsfBj6dsxjX+NPm8U57vfDMQ4S7xQEEDoEEDoEEDoEEDoEEDoEEDoEsEef0u/4LPdY1R5+FjvssZ8373kfq585fNg/316u6BBA6BBA6BBA6BBA6BBA6BBA6BDAInJKY5+5Povnuo/9HPbYz7v3HGMWnxWv3ocTJ04051+/fh19DgeFKzoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEcMPMlObn55vz6kaRv+GhD3+D6saiYaj/jslkMqvTOfBc0SGA0CGA0CGA0CGA0CGA0CGA0CGAPfqUqi8NqHbcPV9c8F/Yg1d2dnZGH2N7e7s5n8XDLVJ4pyCA0CGA0CGA0CGA0CGA0CGA0CGAPfqUFhYWRv1+z47858+fzflB2B/3vA/VHv3IkSOzOp0D77//LwYoCR0CCB0CCB0CCB0CCB0CCB0C2KNPqdqjV/vhns9pz+LZ739atevvea57tUe/evVqc/727dvyNVK4okMAoUMAoUMAoUMAoUMAoUMAoUMAoUMAN8xM6eLFi6N+v+ehEdVNN9WDKaoviZjFF0RUf0d1jj03BVU3F62trZXH4BdXdAggdAggdAggdAggdAggdAggdAhgjz6lzc3N5nx+fr4579lhV3vwagddPdShOn6P6qEQ1WtUe/ZhGIalpaXmfGVlpTwGv7iiQwChQwChQwChQwChQwChQwChQwB79Cm9fv26Ob927Vpzvry8XL7G9+/fpzml/1Pt2Xu+RGIWn1lvuXDhQvkz1f0A7969m9XpHHiu6BBA6BBA6BBA6BBA6BBA6BBA6BBgbq9zYdrzHG6GYXFxsTm/efNmeYzTp08350ePHm3Oq8+C9+zRK9Vz3asd+IcPH8rXePXqVXO+sbFRHiNBT8Ku6BBA6BBA6BBA6BBA6BBA6BBA6BBA6BDADTNTqt6H/X5gwzAMw6lTp5rz8+fPN+fHjx8ffQ6rq6uj5tUXYfT4G/5b/A3cMAMMwyB0iCB0CCB0CCB0CCB0CCB0CND9BQ4pO0k4iFzRIYDQIYDQIYDQIYDQIYDQIYDQIYDQIYDQIcD/AHfff0vZsXOpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(\"../data\", train=True, download=True, transform=ToTensor())\n",
    "image_numpy = train_data[2][0].squeeze().numpy()\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(image_numpy, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41efee06-7e04-461a-b6c4-1272de6fe893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"../data\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=ToTensor(), \n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../data\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1587d8b-a2bb-4fa3-b877-22f124b75624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87824c20-8e36-46b1-bca5-0e5a20ee3570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    label_untransformed = torch.argmax(label).item()\n",
    "    plt.title(labels_map[label_untransformed])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97a47c59-2d89-4a68-86da-04fa9863c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a92ec74e-f0d7-4daf-99b9-d2867dace011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "993a9fb3-d08f-4911-9da2-2a58f2fa1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8398f009-af5d-4b39-819e-166816ab01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "11bd248f-e5b6-4c15-8f0b-dd9121d2c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "50bc8059-dfa6-4860-9ab6-db81e37bc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "870e8110-82e7-422b-b27e-e0e46329f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c71291aa-95b6-4bba-b534-355626c5aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.296603  [   64/60000]\n",
      "loss: 0.441496  [ 6464/60000]\n",
      "loss: 0.266946  [12864/60000]\n",
      "loss: 0.492560  [19264/60000]\n",
      "loss: 0.375201  [25664/60000]\n",
      "loss: 0.410308  [32064/60000]\n",
      "loss: 0.422289  [38464/60000]\n",
      "loss: 0.608139  [44864/60000]\n",
      "loss: 0.536476  [51264/60000]\n",
      "loss: 0.382250  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.447523 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.287618  [   64/60000]\n",
      "loss: 0.439425  [ 6464/60000]\n",
      "loss: 0.265544  [12864/60000]\n",
      "loss: 0.490745  [19264/60000]\n",
      "loss: 0.373767  [25664/60000]\n",
      "loss: 0.408967  [32064/60000]\n",
      "loss: 0.421631  [38464/60000]\n",
      "loss: 0.606370  [44864/60000]\n",
      "loss: 0.534914  [51264/60000]\n",
      "loss: 0.381760  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.446711 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.286198  [   64/60000]\n",
      "loss: 0.437999  [ 6464/60000]\n",
      "loss: 0.264639  [12864/60000]\n",
      "loss: 0.489467  [19264/60000]\n",
      "loss: 0.372295  [25664/60000]\n",
      "loss: 0.407822  [32064/60000]\n",
      "loss: 0.420770  [38464/60000]\n",
      "loss: 0.604605  [44864/60000]\n",
      "loss: 0.533460  [51264/60000]\n",
      "loss: 0.381278  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.445904 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.284861  [   64/60000]\n",
      "loss: 0.436583  [ 6464/60000]\n",
      "loss: 0.263839  [12864/60000]\n",
      "loss: 0.488312  [19264/60000]\n",
      "loss: 0.370807  [25664/60000]\n",
      "loss: 0.406636  [32064/60000]\n",
      "loss: 0.419807  [38464/60000]\n",
      "loss: 0.603006  [44864/60000]\n",
      "loss: 0.532066  [51264/60000]\n",
      "loss: 0.380715  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.445104 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.283571  [   64/60000]\n",
      "loss: 0.435217  [ 6464/60000]\n",
      "loss: 0.263066  [12864/60000]\n",
      "loss: 0.487231  [19264/60000]\n",
      "loss: 0.369199  [25664/60000]\n",
      "loss: 0.405573  [32064/60000]\n",
      "loss: 0.418803  [38464/60000]\n",
      "loss: 0.601428  [44864/60000]\n",
      "loss: 0.530694  [51264/60000]\n",
      "loss: 0.380149  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.444312 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0cf92ecb-8e48-4512-960c-9656193fc02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.159867  [   64/60000]\n",
      "loss: 1.168568  [ 6464/60000]\n",
      "loss: 0.986829  [12864/60000]\n",
      "loss: 1.124264  [19264/60000]\n",
      "loss: 0.997727  [25664/60000]\n",
      "loss: 1.023760  [32064/60000]\n",
      "loss: 1.069972  [38464/60000]\n",
      "loss: 1.000305  [44864/60000]\n",
      "loss: 1.035774  [51264/60000]\n",
      "loss: 0.977884  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.988149 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.041685  [   64/60000]\n",
      "loss: 1.070184  [ 6464/60000]\n",
      "loss: 0.870639  [12864/60000]\n",
      "loss: 1.030080  [19264/60000]\n",
      "loss: 0.906382  [25664/60000]\n",
      "loss: 0.928616  [32064/60000]\n",
      "loss: 0.992950  [38464/60000]\n",
      "loss: 0.925159  [44864/60000]\n",
      "loss: 0.955275  [51264/60000]\n",
      "loss: 0.911881  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.914660 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.954651  [   64/60000]\n",
      "loss: 1.001321  [ 6464/60000]\n",
      "loss: 0.787157  [12864/60000]\n",
      "loss: 0.963463  [19264/60000]\n",
      "loss: 0.844806  [25664/60000]\n",
      "loss: 0.858696  [32064/60000]\n",
      "loss: 0.938748  [38464/60000]\n",
      "loss: 0.874516  [44864/60000]\n",
      "loss: 0.896727  [51264/60000]\n",
      "loss: 0.864287  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.861515 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.887410  [   64/60000]\n",
      "loss: 0.949103  [ 6464/60000]\n",
      "loss: 0.724315  [12864/60000]\n",
      "loss: 0.913696  [19264/60000]\n",
      "loss: 0.800671  [25664/60000]\n",
      "loss: 0.805645  [32064/60000]\n",
      "loss: 0.897206  [38464/60000]\n",
      "loss: 0.839055  [44864/60000]\n",
      "loss: 0.852678  [51264/60000]\n",
      "loss: 0.827509  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.821060 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.833166  [   64/60000]\n",
      "loss: 0.906797  [ 6464/60000]\n",
      "loss: 0.675271  [12864/60000]\n",
      "loss: 0.875125  [19264/60000]\n",
      "loss: 0.767216  [25664/60000]\n",
      "loss: 0.764810  [32064/60000]\n",
      "loss: 0.863106  [38464/60000]\n",
      "loss: 0.813032  [44864/60000]\n",
      "loss: 0.818328  [51264/60000]\n",
      "loss: 0.797554  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.788763 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.788142  [   64/60000]\n",
      "loss: 0.870967  [ 6464/60000]\n",
      "loss: 0.635895  [12864/60000]\n",
      "loss: 0.844230  [19264/60000]\n",
      "loss: 0.740831  [25664/60000]\n",
      "loss: 0.732633  [32064/60000]\n",
      "loss: 0.833598  [38464/60000]\n",
      "loss: 0.792718  [44864/60000]\n",
      "loss: 0.790503  [51264/60000]\n",
      "loss: 0.772053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.761915 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.749922  [   64/60000]\n",
      "loss: 0.839466  [ 6464/60000]\n",
      "loss: 0.603319  [12864/60000]\n",
      "loss: 0.819049  [19264/60000]\n",
      "loss: 0.718885  [25664/60000]\n",
      "loss: 0.706824  [32064/60000]\n",
      "loss: 0.807081  [38464/60000]\n",
      "loss: 0.775882  [44864/60000]\n",
      "loss: 0.767111  [51264/60000]\n",
      "loss: 0.749598  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.738761 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.716877  [   64/60000]\n",
      "loss: 0.811005  [ 6464/60000]\n",
      "loss: 0.575721  [12864/60000]\n",
      "loss: 0.797877  [19264/60000]\n",
      "loss: 0.700018  [25664/60000]\n",
      "loss: 0.685723  [32064/60000]\n",
      "loss: 0.782756  [38464/60000]\n",
      "loss: 0.761252  [44864/60000]\n",
      "loss: 0.747075  [51264/60000]\n",
      "loss: 0.729369  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.718244 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.687778  [   64/60000]\n",
      "loss: 0.784943  [ 6464/60000]\n",
      "loss: 0.551862  [12864/60000]\n",
      "loss: 0.779658  [19264/60000]\n",
      "loss: 0.683405  [25664/60000]\n",
      "loss: 0.668178  [32064/60000]\n",
      "loss: 0.760166  [38464/60000]\n",
      "loss: 0.748244  [44864/60000]\n",
      "loss: 0.729552  [51264/60000]\n",
      "loss: 0.710791  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.699742 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.662024  [   64/60000]\n",
      "loss: 0.760896  [ 6464/60000]\n",
      "loss: 0.530908  [12864/60000]\n",
      "loss: 0.763581  [19264/60000]\n",
      "loss: 0.668625  [25664/60000]\n",
      "loss: 0.653293  [32064/60000]\n",
      "loss: 0.739058  [38464/60000]\n",
      "loss: 0.736555  [44864/60000]\n",
      "loss: 0.714010  [51264/60000]\n",
      "loss: 0.693665  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.682873 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.639123  [   64/60000]\n",
      "loss: 0.738725  [ 6464/60000]\n",
      "loss: 0.512333  [12864/60000]\n",
      "loss: 0.749194  [19264/60000]\n",
      "loss: 0.655527  [25664/60000]\n",
      "loss: 0.640576  [32064/60000]\n",
      "loss: 0.719350  [38464/60000]\n",
      "loss: 0.726036  [44864/60000]\n",
      "loss: 0.700177  [51264/60000]\n",
      "loss: 0.677778  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.667421 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.618669  [   64/60000]\n",
      "loss: 0.718328  [ 6464/60000]\n",
      "loss: 0.495723  [12864/60000]\n",
      "loss: 0.736070  [19264/60000]\n",
      "loss: 0.643814  [25664/60000]\n",
      "loss: 0.629515  [32064/60000]\n",
      "loss: 0.700951  [38464/60000]\n",
      "loss: 0.716713  [44864/60000]\n",
      "loss: 0.687934  [51264/60000]\n",
      "loss: 0.662938  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.653246 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.600304  [   64/60000]\n",
      "loss: 0.699605  [ 6464/60000]\n",
      "loss: 0.480854  [12864/60000]\n",
      "loss: 0.724000  [19264/60000]\n",
      "loss: 0.633304  [25664/60000]\n",
      "loss: 0.619888  [32064/60000]\n",
      "loss: 0.683787  [38464/60000]\n",
      "loss: 0.708645  [44864/60000]\n",
      "loss: 0.677230  [51264/60000]\n",
      "loss: 0.649050  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.640241 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.583734  [   64/60000]\n",
      "loss: 0.682513  [ 6464/60000]\n",
      "loss: 0.467410  [12864/60000]\n",
      "loss: 0.712833  [19264/60000]\n",
      "loss: 0.623896  [25664/60000]\n",
      "loss: 0.611408  [32064/60000]\n",
      "loss: 0.667904  [38464/60000]\n",
      "loss: 0.701735  [44864/60000]\n",
      "loss: 0.667970  [51264/60000]\n",
      "loss: 0.636093  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.628308 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.568693  [   64/60000]\n",
      "loss: 0.666861  [ 6464/60000]\n",
      "loss: 0.455195  [12864/60000]\n",
      "loss: 0.702418  [19264/60000]\n",
      "loss: 0.615425  [25664/60000]\n",
      "loss: 0.603893  [32064/60000]\n",
      "loss: 0.653301  [38464/60000]\n",
      "loss: 0.695881  [44864/60000]\n",
      "loss: 0.659980  [51264/60000]\n",
      "loss: 0.623995  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.617370 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.554997  [   64/60000]\n",
      "loss: 0.652581  [ 6464/60000]\n",
      "loss: 0.444059  [12864/60000]\n",
      "loss: 0.692760  [19264/60000]\n",
      "loss: 0.607652  [25664/60000]\n",
      "loss: 0.597137  [32064/60000]\n",
      "loss: 0.639819  [38464/60000]\n",
      "loss: 0.690996  [44864/60000]\n",
      "loss: 0.653222  [51264/60000]\n",
      "loss: 0.612691  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.607338 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.542429  [   64/60000]\n",
      "loss: 0.639572  [ 6464/60000]\n",
      "loss: 0.433836  [12864/60000]\n",
      "loss: 0.683765  [19264/60000]\n",
      "loss: 0.600374  [25664/60000]\n",
      "loss: 0.590995  [32064/60000]\n",
      "loss: 0.627467  [38464/60000]\n",
      "loss: 0.687003  [44864/60000]\n",
      "loss: 0.647436  [51264/60000]\n",
      "loss: 0.602003  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.598122 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.530872  [   64/60000]\n",
      "loss: 0.627697  [ 6464/60000]\n",
      "loss: 0.424506  [12864/60000]\n",
      "loss: 0.675306  [19264/60000]\n",
      "loss: 0.593551  [25664/60000]\n",
      "loss: 0.585346  [32064/60000]\n",
      "loss: 0.616131  [38464/60000]\n",
      "loss: 0.683836  [44864/60000]\n",
      "loss: 0.642500  [51264/60000]\n",
      "loss: 0.591845  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.589646 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.520196  [   64/60000]\n",
      "loss: 0.616816  [ 6464/60000]\n",
      "loss: 0.415916  [12864/60000]\n",
      "loss: 0.667346  [19264/60000]\n",
      "loss: 0.586999  [25664/60000]\n",
      "loss: 0.580039  [32064/60000]\n",
      "loss: 0.605738  [38464/60000]\n",
      "loss: 0.681462  [44864/60000]\n",
      "loss: 0.638232  [51264/60000]\n",
      "loss: 0.582130  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.581839 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.510305  [   64/60000]\n",
      "loss: 0.606863  [ 6464/60000]\n",
      "loss: 0.407932  [12864/60000]\n",
      "loss: 0.659832  [19264/60000]\n",
      "loss: 0.580664  [25664/60000]\n",
      "loss: 0.574982  [32064/60000]\n",
      "loss: 0.596257  [38464/60000]\n",
      "loss: 0.679759  [44864/60000]\n",
      "loss: 0.634576  [51264/60000]\n",
      "loss: 0.572857  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.574638 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.501103  [   64/60000]\n",
      "loss: 0.597759  [ 6464/60000]\n",
      "loss: 0.400543  [12864/60000]\n",
      "loss: 0.652729  [19264/60000]\n",
      "loss: 0.574469  [25664/60000]\n",
      "loss: 0.570140  [32064/60000]\n",
      "loss: 0.587588  [38464/60000]\n",
      "loss: 0.678603  [44864/60000]\n",
      "loss: 0.631382  [51264/60000]\n",
      "loss: 0.563922  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.567982 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.492461  [   64/60000]\n",
      "loss: 0.589394  [ 6464/60000]\n",
      "loss: 0.393708  [12864/60000]\n",
      "loss: 0.645982  [19264/60000]\n",
      "loss: 0.568360  [25664/60000]\n",
      "loss: 0.565408  [32064/60000]\n",
      "loss: 0.579655  [38464/60000]\n",
      "loss: 0.677877  [44864/60000]\n",
      "loss: 0.628595  [51264/60000]\n",
      "loss: 0.555289  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.561818 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.484334  [   64/60000]\n",
      "loss: 0.581740  [ 6464/60000]\n",
      "loss: 0.387337  [12864/60000]\n",
      "loss: 0.639567  [19264/60000]\n",
      "loss: 0.562329  [25664/60000]\n",
      "loss: 0.560711  [32064/60000]\n",
      "loss: 0.572284  [38464/60000]\n",
      "loss: 0.677544  [44864/60000]\n",
      "loss: 0.626093  [51264/60000]\n",
      "loss: 0.546952  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.556100 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.476670  [   64/60000]\n",
      "loss: 0.574747  [ 6464/60000]\n",
      "loss: 0.381404  [12864/60000]\n",
      "loss: 0.633441  [19264/60000]\n",
      "loss: 0.556471  [25664/60000]\n",
      "loss: 0.556088  [32064/60000]\n",
      "loss: 0.565423  [38464/60000]\n",
      "loss: 0.677570  [44864/60000]\n",
      "loss: 0.623819  [51264/60000]\n",
      "loss: 0.538894  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.550793 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.469362  [   64/60000]\n",
      "loss: 0.568305  [ 6464/60000]\n",
      "loss: 0.375889  [12864/60000]\n",
      "loss: 0.627635  [19264/60000]\n",
      "loss: 0.550638  [25664/60000]\n",
      "loss: 0.551510  [32064/60000]\n",
      "loss: 0.559055  [38464/60000]\n",
      "loss: 0.677874  [44864/60000]\n",
      "loss: 0.621728  [51264/60000]\n",
      "loss: 0.531158  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.545853 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.462454  [   64/60000]\n",
      "loss: 0.562352  [ 6464/60000]\n",
      "loss: 0.370696  [12864/60000]\n",
      "loss: 0.622098  [19264/60000]\n",
      "loss: 0.544756  [25664/60000]\n",
      "loss: 0.546938  [32064/60000]\n",
      "loss: 0.553100  [38464/60000]\n",
      "loss: 0.678258  [44864/60000]\n",
      "loss: 0.619777  [51264/60000]\n",
      "loss: 0.523620  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.541243 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.455858  [   64/60000]\n",
      "loss: 0.556857  [ 6464/60000]\n",
      "loss: 0.365838  [12864/60000]\n",
      "loss: 0.616723  [19264/60000]\n",
      "loss: 0.538991  [25664/60000]\n",
      "loss: 0.542349  [32064/60000]\n",
      "loss: 0.547553  [38464/60000]\n",
      "loss: 0.678714  [44864/60000]\n",
      "loss: 0.617931  [51264/60000]\n",
      "loss: 0.516347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.536945 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.449621  [   64/60000]\n",
      "loss: 0.551754  [ 6464/60000]\n",
      "loss: 0.361312  [12864/60000]\n",
      "loss: 0.611601  [19264/60000]\n",
      "loss: 0.533466  [25664/60000]\n",
      "loss: 0.537775  [32064/60000]\n",
      "loss: 0.542361  [38464/60000]\n",
      "loss: 0.679229  [44864/60000]\n",
      "loss: 0.616171  [51264/60000]\n",
      "loss: 0.509373  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.532929 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.443741  [   64/60000]\n",
      "loss: 0.547065  [ 6464/60000]\n",
      "loss: 0.357077  [12864/60000]\n",
      "loss: 0.606718  [19264/60000]\n",
      "loss: 0.528095  [25664/60000]\n",
      "loss: 0.533182  [32064/60000]\n",
      "loss: 0.537575  [38464/60000]\n",
      "loss: 0.679767  [44864/60000]\n",
      "loss: 0.614544  [51264/60000]\n",
      "loss: 0.502710  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.529167 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.438089  [   64/60000]\n",
      "loss: 0.542760  [ 6464/60000]\n",
      "loss: 0.353110  [12864/60000]\n",
      "loss: 0.602055  [19264/60000]\n",
      "loss: 0.522890  [25664/60000]\n",
      "loss: 0.528718  [32064/60000]\n",
      "loss: 0.533073  [38464/60000]\n",
      "loss: 0.680188  [44864/60000]\n",
      "loss: 0.612899  [51264/60000]\n",
      "loss: 0.496343  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.525636 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.432623  [   64/60000]\n",
      "loss: 0.538800  [ 6464/60000]\n",
      "loss: 0.349407  [12864/60000]\n",
      "loss: 0.597601  [19264/60000]\n",
      "loss: 0.517839  [25664/60000]\n",
      "loss: 0.524329  [32064/60000]\n",
      "loss: 0.528823  [38464/60000]\n",
      "loss: 0.680523  [44864/60000]\n",
      "loss: 0.611224  [51264/60000]\n",
      "loss: 0.490216  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.522304 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.427380  [   64/60000]\n",
      "loss: 0.535140  [ 6464/60000]\n",
      "loss: 0.345919  [12864/60000]\n",
      "loss: 0.593331  [19264/60000]\n",
      "loss: 0.512881  [25664/60000]\n",
      "loss: 0.519935  [32064/60000]\n",
      "loss: 0.524780  [38464/60000]\n",
      "loss: 0.680710  [44864/60000]\n",
      "loss: 0.609494  [51264/60000]\n",
      "loss: 0.484371  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.519165 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.422283  [   64/60000]\n",
      "loss: 0.531746  [ 6464/60000]\n",
      "loss: 0.342540  [12864/60000]\n",
      "loss: 0.589250  [19264/60000]\n",
      "loss: 0.508035  [25664/60000]\n",
      "loss: 0.515560  [32064/60000]\n",
      "loss: 0.520913  [38464/60000]\n",
      "loss: 0.680756  [44864/60000]\n",
      "loss: 0.607853  [51264/60000]\n",
      "loss: 0.478816  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.516201 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.417392  [   64/60000]\n",
      "loss: 0.528561  [ 6464/60000]\n",
      "loss: 0.339311  [12864/60000]\n",
      "loss: 0.585288  [19264/60000]\n",
      "loss: 0.503465  [25664/60000]\n",
      "loss: 0.511314  [32064/60000]\n",
      "loss: 0.517171  [38464/60000]\n",
      "loss: 0.680608  [44864/60000]\n",
      "loss: 0.606179  [51264/60000]\n",
      "loss: 0.473565  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.513395 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.412658  [   64/60000]\n",
      "loss: 0.525541  [ 6464/60000]\n",
      "loss: 0.336209  [12864/60000]\n",
      "loss: 0.581467  [19264/60000]\n",
      "loss: 0.498947  [25664/60000]\n",
      "loss: 0.507219  [32064/60000]\n",
      "loss: 0.513602  [38464/60000]\n",
      "loss: 0.680345  [44864/60000]\n",
      "loss: 0.604511  [51264/60000]\n",
      "loss: 0.468592  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.510730 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.408089  [   64/60000]\n",
      "loss: 0.522644  [ 6464/60000]\n",
      "loss: 0.333257  [12864/60000]\n",
      "loss: 0.577784  [19264/60000]\n",
      "loss: 0.494554  [25664/60000]\n",
      "loss: 0.503224  [32064/60000]\n",
      "loss: 0.510217  [38464/60000]\n",
      "loss: 0.679928  [44864/60000]\n",
      "loss: 0.602849  [51264/60000]\n",
      "loss: 0.463889  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.508194 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.403629  [   64/60000]\n",
      "loss: 0.519884  [ 6464/60000]\n",
      "loss: 0.330455  [12864/60000]\n",
      "loss: 0.574165  [19264/60000]\n",
      "loss: 0.490272  [25664/60000]\n",
      "loss: 0.499384  [32064/60000]\n",
      "loss: 0.506957  [38464/60000]\n",
      "loss: 0.679374  [44864/60000]\n",
      "loss: 0.601228  [51264/60000]\n",
      "loss: 0.459401  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.505779 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.399251  [   64/60000]\n",
      "loss: 0.517272  [ 6464/60000]\n",
      "loss: 0.327791  [12864/60000]\n",
      "loss: 0.570706  [19264/60000]\n",
      "loss: 0.486148  [25664/60000]\n",
      "loss: 0.495689  [32064/60000]\n",
      "loss: 0.503824  [38464/60000]\n",
      "loss: 0.678703  [44864/60000]\n",
      "loss: 0.599609  [51264/60000]\n",
      "loss: 0.455106  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.503473 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.394954  [   64/60000]\n",
      "loss: 0.514752  [ 6464/60000]\n",
      "loss: 0.325269  [12864/60000]\n",
      "loss: 0.567405  [19264/60000]\n",
      "loss: 0.482152  [25664/60000]\n",
      "loss: 0.492082  [32064/60000]\n",
      "loss: 0.500759  [38464/60000]\n",
      "loss: 0.677882  [44864/60000]\n",
      "loss: 0.597913  [51264/60000]\n",
      "loss: 0.451001  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.501263 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.390765  [   64/60000]\n",
      "loss: 0.512358  [ 6464/60000]\n",
      "loss: 0.322830  [12864/60000]\n",
      "loss: 0.564243  [19264/60000]\n",
      "loss: 0.478262  [25664/60000]\n",
      "loss: 0.488572  [32064/60000]\n",
      "loss: 0.497805  [38464/60000]\n",
      "loss: 0.676962  [44864/60000]\n",
      "loss: 0.596190  [51264/60000]\n",
      "loss: 0.447110  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.499138 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.386665  [   64/60000]\n",
      "loss: 0.510080  [ 6464/60000]\n",
      "loss: 0.320455  [12864/60000]\n",
      "loss: 0.561166  [19264/60000]\n",
      "loss: 0.474434  [25664/60000]\n",
      "loss: 0.485123  [32064/60000]\n",
      "loss: 0.494946  [38464/60000]\n",
      "loss: 0.675892  [44864/60000]\n",
      "loss: 0.594457  [51264/60000]\n",
      "loss: 0.443408  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497094 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.382684  [   64/60000]\n",
      "loss: 0.507866  [ 6464/60000]\n",
      "loss: 0.318177  [12864/60000]\n",
      "loss: 0.558182  [19264/60000]\n",
      "loss: 0.470652  [25664/60000]\n",
      "loss: 0.481795  [32064/60000]\n",
      "loss: 0.492142  [38464/60000]\n",
      "loss: 0.674708  [44864/60000]\n",
      "loss: 0.592766  [51264/60000]\n",
      "loss: 0.439920  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.495123 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.378855  [   64/60000]\n",
      "loss: 0.505699  [ 6464/60000]\n",
      "loss: 0.315927  [12864/60000]\n",
      "loss: 0.555385  [19264/60000]\n",
      "loss: 0.466886  [25664/60000]\n",
      "loss: 0.478629  [32064/60000]\n",
      "loss: 0.489416  [38464/60000]\n",
      "loss: 0.673404  [44864/60000]\n",
      "loss: 0.591128  [51264/60000]\n",
      "loss: 0.436619  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.493229 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.375111  [   64/60000]\n",
      "loss: 0.503574  [ 6464/60000]\n",
      "loss: 0.313827  [12864/60000]\n",
      "loss: 0.552646  [19264/60000]\n",
      "loss: 0.463364  [25664/60000]\n",
      "loss: 0.475496  [32064/60000]\n",
      "loss: 0.486553  [38464/60000]\n",
      "loss: 0.672041  [44864/60000]\n",
      "loss: 0.589439  [51264/60000]\n",
      "loss: 0.433473  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.491388 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.371347  [   64/60000]\n",
      "loss: 0.501544  [ 6464/60000]\n",
      "loss: 0.311623  [12864/60000]\n",
      "loss: 0.549990  [19264/60000]\n",
      "loss: 0.460047  [25664/60000]\n",
      "loss: 0.472448  [32064/60000]\n",
      "loss: 0.483649  [38464/60000]\n",
      "loss: 0.670702  [44864/60000]\n",
      "loss: 0.587760  [51264/60000]\n",
      "loss: 0.430491  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.489600 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.367797  [   64/60000]\n",
      "loss: 0.499602  [ 6464/60000]\n",
      "loss: 0.309397  [12864/60000]\n",
      "loss: 0.547431  [19264/60000]\n",
      "loss: 0.456941  [25664/60000]\n",
      "loss: 0.469475  [32064/60000]\n",
      "loss: 0.480789  [38464/60000]\n",
      "loss: 0.669269  [44864/60000]\n",
      "loss: 0.586160  [51264/60000]\n",
      "loss: 0.427514  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.487883 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.364396  [   64/60000]\n",
      "loss: 0.497685  [ 6464/60000]\n",
      "loss: 0.307365  [12864/60000]\n",
      "loss: 0.544858  [19264/60000]\n",
      "loss: 0.453914  [25664/60000]\n",
      "loss: 0.466755  [32064/60000]\n",
      "loss: 0.478163  [38464/60000]\n",
      "loss: 0.667782  [44864/60000]\n",
      "loss: 0.584559  [51264/60000]\n",
      "loss: 0.424751  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.486234 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.361012  [   64/60000]\n",
      "loss: 0.495671  [ 6464/60000]\n",
      "loss: 0.305511  [12864/60000]\n",
      "loss: 0.542452  [19264/60000]\n",
      "loss: 0.450929  [25664/60000]\n",
      "loss: 0.464086  [32064/60000]\n",
      "loss: 0.475842  [38464/60000]\n",
      "loss: 0.666198  [44864/60000]\n",
      "loss: 0.583012  [51264/60000]\n",
      "loss: 0.422219  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.484637 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.357705  [   64/60000]\n",
      "loss: 0.493733  [ 6464/60000]\n",
      "loss: 0.303684  [12864/60000]\n",
      "loss: 0.540171  [19264/60000]\n",
      "loss: 0.447945  [25664/60000]\n",
      "loss: 0.461565  [32064/60000]\n",
      "loss: 0.473657  [38464/60000]\n",
      "loss: 0.664558  [44864/60000]\n",
      "loss: 0.581429  [51264/60000]\n",
      "loss: 0.419765  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.483083 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.354495  [   64/60000]\n",
      "loss: 0.491816  [ 6464/60000]\n",
      "loss: 0.301979  [12864/60000]\n",
      "loss: 0.537993  [19264/60000]\n",
      "loss: 0.445050  [25664/60000]\n",
      "loss: 0.459086  [32064/60000]\n",
      "loss: 0.471497  [38464/60000]\n",
      "loss: 0.662781  [44864/60000]\n",
      "loss: 0.579871  [51264/60000]\n",
      "loss: 0.417502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.481576 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.351429  [   64/60000]\n",
      "loss: 0.489919  [ 6464/60000]\n",
      "loss: 0.300349  [12864/60000]\n",
      "loss: 0.535935  [19264/60000]\n",
      "loss: 0.442250  [25664/60000]\n",
      "loss: 0.456683  [32064/60000]\n",
      "loss: 0.469413  [38464/60000]\n",
      "loss: 0.661023  [44864/60000]\n",
      "loss: 0.578353  [51264/60000]\n",
      "loss: 0.415343  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.480118 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.348415  [   64/60000]\n",
      "loss: 0.488139  [ 6464/60000]\n",
      "loss: 0.298748  [12864/60000]\n",
      "loss: 0.533842  [19264/60000]\n",
      "loss: 0.439486  [25664/60000]\n",
      "loss: 0.454409  [32064/60000]\n",
      "loss: 0.467388  [38464/60000]\n",
      "loss: 0.659285  [44864/60000]\n",
      "loss: 0.576862  [51264/60000]\n",
      "loss: 0.413347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.478701 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.345484  [   64/60000]\n",
      "loss: 0.486420  [ 6464/60000]\n",
      "loss: 0.297159  [12864/60000]\n",
      "loss: 0.531831  [19264/60000]\n",
      "loss: 0.436791  [25664/60000]\n",
      "loss: 0.452195  [32064/60000]\n",
      "loss: 0.465402  [38464/60000]\n",
      "loss: 0.657484  [44864/60000]\n",
      "loss: 0.575330  [51264/60000]\n",
      "loss: 0.411480  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.477317 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.342694  [   64/60000]\n",
      "loss: 0.484700  [ 6464/60000]\n",
      "loss: 0.295653  [12864/60000]\n",
      "loss: 0.529911  [19264/60000]\n",
      "loss: 0.434139  [25664/60000]\n",
      "loss: 0.450000  [32064/60000]\n",
      "loss: 0.463473  [38464/60000]\n",
      "loss: 0.655721  [44864/60000]\n",
      "loss: 0.573803  [51264/60000]\n",
      "loss: 0.409741  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.475967 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.339930  [   64/60000]\n",
      "loss: 0.483067  [ 6464/60000]\n",
      "loss: 0.294140  [12864/60000]\n",
      "loss: 0.528021  [19264/60000]\n",
      "loss: 0.431536  [25664/60000]\n",
      "loss: 0.447926  [32064/60000]\n",
      "loss: 0.461632  [38464/60000]\n",
      "loss: 0.654007  [44864/60000]\n",
      "loss: 0.572323  [51264/60000]\n",
      "loss: 0.408065  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.474651 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.337202  [   64/60000]\n",
      "loss: 0.481385  [ 6464/60000]\n",
      "loss: 0.292688  [12864/60000]\n",
      "loss: 0.526171  [19264/60000]\n",
      "loss: 0.428932  [25664/60000]\n",
      "loss: 0.445940  [32064/60000]\n",
      "loss: 0.459796  [38464/60000]\n",
      "loss: 0.652188  [44864/60000]\n",
      "loss: 0.570821  [51264/60000]\n",
      "loss: 0.406426  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.473368 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.334502  [   64/60000]\n",
      "loss: 0.479713  [ 6464/60000]\n",
      "loss: 0.291282  [12864/60000]\n",
      "loss: 0.524386  [19264/60000]\n",
      "loss: 0.426353  [25664/60000]\n",
      "loss: 0.444035  [32064/60000]\n",
      "loss: 0.457986  [38464/60000]\n",
      "loss: 0.650387  [44864/60000]\n",
      "loss: 0.569385  [51264/60000]\n",
      "loss: 0.404875  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.472113 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.331817  [   64/60000]\n",
      "loss: 0.478098  [ 6464/60000]\n",
      "loss: 0.289909  [12864/60000]\n",
      "loss: 0.522650  [19264/60000]\n",
      "loss: 0.423857  [25664/60000]\n",
      "loss: 0.442265  [32064/60000]\n",
      "loss: 0.456210  [38464/60000]\n",
      "loss: 0.648571  [44864/60000]\n",
      "loss: 0.567910  [51264/60000]\n",
      "loss: 0.403394  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.470887 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.329233  [   64/60000]\n",
      "loss: 0.476480  [ 6464/60000]\n",
      "loss: 0.288608  [12864/60000]\n",
      "loss: 0.520931  [19264/60000]\n",
      "loss: 0.421336  [25664/60000]\n",
      "loss: 0.440525  [32064/60000]\n",
      "loss: 0.454487  [38464/60000]\n",
      "loss: 0.646769  [44864/60000]\n",
      "loss: 0.566484  [51264/60000]\n",
      "loss: 0.401982  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.469689 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.326716  [   64/60000]\n",
      "loss: 0.474881  [ 6464/60000]\n",
      "loss: 0.287326  [12864/60000]\n",
      "loss: 0.519284  [19264/60000]\n",
      "loss: 0.418898  [25664/60000]\n",
      "loss: 0.438864  [32064/60000]\n",
      "loss: 0.452791  [38464/60000]\n",
      "loss: 0.644988  [44864/60000]\n",
      "loss: 0.565062  [51264/60000]\n",
      "loss: 0.400645  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.468514 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.324297  [   64/60000]\n",
      "loss: 0.473292  [ 6464/60000]\n",
      "loss: 0.286118  [12864/60000]\n",
      "loss: 0.517666  [19264/60000]\n",
      "loss: 0.416514  [25664/60000]\n",
      "loss: 0.437223  [32064/60000]\n",
      "loss: 0.451148  [38464/60000]\n",
      "loss: 0.643168  [44864/60000]\n",
      "loss: 0.563581  [51264/60000]\n",
      "loss: 0.399337  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.467362 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.321951  [   64/60000]\n",
      "loss: 0.471691  [ 6464/60000]\n",
      "loss: 0.284930  [12864/60000]\n",
      "loss: 0.516058  [19264/60000]\n",
      "loss: 0.414166  [25664/60000]\n",
      "loss: 0.435607  [32064/60000]\n",
      "loss: 0.449467  [38464/60000]\n",
      "loss: 0.641399  [44864/60000]\n",
      "loss: 0.562147  [51264/60000]\n",
      "loss: 0.398071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.466232 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.319672  [   64/60000]\n",
      "loss: 0.470046  [ 6464/60000]\n",
      "loss: 0.283763  [12864/60000]\n",
      "loss: 0.514535  [19264/60000]\n",
      "loss: 0.411912  [25664/60000]\n",
      "loss: 0.434123  [32064/60000]\n",
      "loss: 0.447843  [38464/60000]\n",
      "loss: 0.639637  [44864/60000]\n",
      "loss: 0.560711  [51264/60000]\n",
      "loss: 0.396870  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.465125 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.317452  [   64/60000]\n",
      "loss: 0.468403  [ 6464/60000]\n",
      "loss: 0.282680  [12864/60000]\n",
      "loss: 0.513090  [19264/60000]\n",
      "loss: 0.409631  [25664/60000]\n",
      "loss: 0.432664  [32064/60000]\n",
      "loss: 0.446247  [38464/60000]\n",
      "loss: 0.637830  [44864/60000]\n",
      "loss: 0.559286  [51264/60000]\n",
      "loss: 0.395741  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.464040 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.315288  [   64/60000]\n",
      "loss: 0.466773  [ 6464/60000]\n",
      "loss: 0.281599  [12864/60000]\n",
      "loss: 0.511691  [19264/60000]\n",
      "loss: 0.407425  [25664/60000]\n",
      "loss: 0.431186  [32064/60000]\n",
      "loss: 0.444707  [38464/60000]\n",
      "loss: 0.636055  [44864/60000]\n",
      "loss: 0.557763  [51264/60000]\n",
      "loss: 0.394617  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.462971 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.313196  [   64/60000]\n",
      "loss: 0.465151  [ 6464/60000]\n",
      "loss: 0.280531  [12864/60000]\n",
      "loss: 0.510315  [19264/60000]\n",
      "loss: 0.405249  [25664/60000]\n",
      "loss: 0.429764  [32064/60000]\n",
      "loss: 0.443181  [38464/60000]\n",
      "loss: 0.634383  [44864/60000]\n",
      "loss: 0.556304  [51264/60000]\n",
      "loss: 0.393590  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.461926 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.311158  [   64/60000]\n",
      "loss: 0.463546  [ 6464/60000]\n",
      "loss: 0.279504  [12864/60000]\n",
      "loss: 0.508927  [19264/60000]\n",
      "loss: 0.403150  [25664/60000]\n",
      "loss: 0.428341  [32064/60000]\n",
      "loss: 0.441716  [38464/60000]\n",
      "loss: 0.632720  [44864/60000]\n",
      "loss: 0.554905  [51264/60000]\n",
      "loss: 0.392612  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.460899 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.309197  [   64/60000]\n",
      "loss: 0.461983  [ 6464/60000]\n",
      "loss: 0.278498  [12864/60000]\n",
      "loss: 0.507622  [19264/60000]\n",
      "loss: 0.401038  [25664/60000]\n",
      "loss: 0.426980  [32064/60000]\n",
      "loss: 0.440254  [38464/60000]\n",
      "loss: 0.631044  [44864/60000]\n",
      "loss: 0.553474  [51264/60000]\n",
      "loss: 0.391681  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.459885 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.307297  [   64/60000]\n",
      "loss: 0.460387  [ 6464/60000]\n",
      "loss: 0.277503  [12864/60000]\n",
      "loss: 0.506326  [19264/60000]\n",
      "loss: 0.398978  [25664/60000]\n",
      "loss: 0.425650  [32064/60000]\n",
      "loss: 0.438843  [38464/60000]\n",
      "loss: 0.629394  [44864/60000]\n",
      "loss: 0.552124  [51264/60000]\n",
      "loss: 0.390807  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.458889 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.305454  [   64/60000]\n",
      "loss: 0.458805  [ 6464/60000]\n",
      "loss: 0.276546  [12864/60000]\n",
      "loss: 0.505030  [19264/60000]\n",
      "loss: 0.396974  [25664/60000]\n",
      "loss: 0.424341  [32064/60000]\n",
      "loss: 0.437447  [38464/60000]\n",
      "loss: 0.627698  [44864/60000]\n",
      "loss: 0.550730  [51264/60000]\n",
      "loss: 0.389922  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.457909 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.303664  [   64/60000]\n",
      "loss: 0.457229  [ 6464/60000]\n",
      "loss: 0.275594  [12864/60000]\n",
      "loss: 0.503781  [19264/60000]\n",
      "loss: 0.395010  [25664/60000]\n",
      "loss: 0.423045  [32064/60000]\n",
      "loss: 0.436088  [38464/60000]\n",
      "loss: 0.625932  [44864/60000]\n",
      "loss: 0.549344  [51264/60000]\n",
      "loss: 0.389057  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.456949 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.301937  [   64/60000]\n",
      "loss: 0.455642  [ 6464/60000]\n",
      "loss: 0.274636  [12864/60000]\n",
      "loss: 0.502561  [19264/60000]\n",
      "loss: 0.393024  [25664/60000]\n",
      "loss: 0.421762  [32064/60000]\n",
      "loss: 0.434755  [38464/60000]\n",
      "loss: 0.624130  [44864/60000]\n",
      "loss: 0.547956  [51264/60000]\n",
      "loss: 0.388252  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.456004 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.300269  [   64/60000]\n",
      "loss: 0.454056  [ 6464/60000]\n",
      "loss: 0.273715  [12864/60000]\n",
      "loss: 0.501346  [19264/60000]\n",
      "loss: 0.391104  [25664/60000]\n",
      "loss: 0.420470  [32064/60000]\n",
      "loss: 0.433422  [38464/60000]\n",
      "loss: 0.622325  [44864/60000]\n",
      "loss: 0.546536  [51264/60000]\n",
      "loss: 0.387485  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.455072 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.298691  [   64/60000]\n",
      "loss: 0.452527  [ 6464/60000]\n",
      "loss: 0.272780  [12864/60000]\n",
      "loss: 0.500161  [19264/60000]\n",
      "loss: 0.389229  [25664/60000]\n",
      "loss: 0.419245  [32064/60000]\n",
      "loss: 0.432142  [38464/60000]\n",
      "loss: 0.620472  [44864/60000]\n",
      "loss: 0.545191  [51264/60000]\n",
      "loss: 0.386748  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.454156 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.297155  [   64/60000]\n",
      "loss: 0.450947  [ 6464/60000]\n",
      "loss: 0.271855  [12864/60000]\n",
      "loss: 0.498996  [19264/60000]\n",
      "loss: 0.387366  [25664/60000]\n",
      "loss: 0.418013  [32064/60000]\n",
      "loss: 0.430911  [38464/60000]\n",
      "loss: 0.618736  [44864/60000]\n",
      "loss: 0.543907  [51264/60000]\n",
      "loss: 0.386045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.453254 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.295661  [   64/60000]\n",
      "loss: 0.449389  [ 6464/60000]\n",
      "loss: 0.270950  [12864/60000]\n",
      "loss: 0.497853  [19264/60000]\n",
      "loss: 0.385556  [25664/60000]\n",
      "loss: 0.416809  [32064/60000]\n",
      "loss: 0.429699  [38464/60000]\n",
      "loss: 0.616994  [44864/60000]\n",
      "loss: 0.542678  [51264/60000]\n",
      "loss: 0.385391  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.452360 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.294260  [   64/60000]\n",
      "loss: 0.447874  [ 6464/60000]\n",
      "loss: 0.270063  [12864/60000]\n",
      "loss: 0.496705  [19264/60000]\n",
      "loss: 0.383799  [25664/60000]\n",
      "loss: 0.415616  [32064/60000]\n",
      "loss: 0.428538  [38464/60000]\n",
      "loss: 0.615262  [44864/60000]\n",
      "loss: 0.541396  [51264/60000]\n",
      "loss: 0.384762  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.451471 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.292878  [   64/60000]\n",
      "loss: 0.446343  [ 6464/60000]\n",
      "loss: 0.269198  [12864/60000]\n",
      "loss: 0.495560  [19264/60000]\n",
      "loss: 0.382021  [25664/60000]\n",
      "loss: 0.414389  [32064/60000]\n",
      "loss: 0.427332  [38464/60000]\n",
      "loss: 0.613531  [44864/60000]\n",
      "loss: 0.540096  [51264/60000]\n",
      "loss: 0.384129  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.450593 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.291515  [   64/60000]\n",
      "loss: 0.444830  [ 6464/60000]\n",
      "loss: 0.268327  [12864/60000]\n",
      "loss: 0.494462  [19264/60000]\n",
      "loss: 0.380295  [25664/60000]\n",
      "loss: 0.413203  [32064/60000]\n",
      "loss: 0.426218  [38464/60000]\n",
      "loss: 0.611827  [44864/60000]\n",
      "loss: 0.538840  [51264/60000]\n",
      "loss: 0.383531  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.449729 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.290211  [   64/60000]\n",
      "loss: 0.443352  [ 6464/60000]\n",
      "loss: 0.267463  [12864/60000]\n",
      "loss: 0.493327  [19264/60000]\n",
      "loss: 0.378562  [25664/60000]\n",
      "loss: 0.412063  [32064/60000]\n",
      "loss: 0.425108  [38464/60000]\n",
      "loss: 0.610122  [44864/60000]\n",
      "loss: 0.537616  [51264/60000]\n",
      "loss: 0.382950  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.448874 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.288964  [   64/60000]\n",
      "loss: 0.441898  [ 6464/60000]\n",
      "loss: 0.266626  [12864/60000]\n",
      "loss: 0.492198  [19264/60000]\n",
      "loss: 0.376883  [25664/60000]\n",
      "loss: 0.410834  [32064/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[128], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction error\u001b[39;49;00m\n",
      "File \u001b[0;32m~/main/dlprac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/main/dlprac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/main/dlprac/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/main/dlprac/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/main/dlprac/lib/python3.11/site-packages/torchvision/datasets/mnist.py:139\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5618e0ef-091a-43e6-80dd-986e272499f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "61f57736-26a0-4778-aefb-1753d2b8d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "deep_model = NeuralNetwork().to(device)\n",
    "print(deep_model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "deep_optimizer = torch.optim.SGD(deep_model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb4bdd69-fdcb-4e74-8f75-e794af18b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306765  [   64/60000]\n",
      "loss: 2.306534  [ 6464/60000]\n",
      "loss: 2.300381  [12864/60000]\n",
      "loss: 2.305254  [19264/60000]\n",
      "loss: 2.302912  [25664/60000]\n",
      "loss: 2.306681  [32064/60000]\n",
      "loss: 2.305102  [38464/60000]\n",
      "loss: 2.301619  [44864/60000]\n",
      "loss: 2.304547  [51264/60000]\n",
      "loss: 2.308403  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.302909 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.302572  [   64/60000]\n",
      "loss: 2.306072  [ 6464/60000]\n",
      "loss: 2.300130  [12864/60000]\n",
      "loss: 2.305027  [19264/60000]\n",
      "loss: 2.302735  [25664/60000]\n",
      "loss: 2.306324  [32064/60000]\n",
      "loss: 2.304688  [38464/60000]\n",
      "loss: 2.301164  [44864/60000]\n",
      "loss: 2.303804  [51264/60000]\n",
      "loss: 2.307052  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.301552 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.301277  [   64/60000]\n",
      "loss: 2.303847  [ 6464/60000]\n",
      "loss: 2.291333  [12864/60000]\n",
      "loss: 2.115259  [19264/60000]\n",
      "loss: 1.594249  [25664/60000]\n",
      "loss: 1.612331  [32064/60000]\n",
      "loss: 1.492359  [38464/60000]\n",
      "loss: 1.226120  [44864/60000]\n",
      "loss: 1.066379  [51264/60000]\n",
      "loss: 0.970664  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.890182 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.894666  [   64/60000]\n",
      "loss: 0.835272  [ 6464/60000]\n",
      "loss: 0.668006  [12864/60000]\n",
      "loss: 0.768780  [19264/60000]\n",
      "loss: 0.630747  [25664/60000]\n",
      "loss: 1.020985  [32064/60000]\n",
      "loss: 0.851226  [38464/60000]\n",
      "loss: 0.729627  [44864/60000]\n",
      "loss: 0.847115  [51264/60000]\n",
      "loss: 0.533539  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.613749 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.545556  [   64/60000]\n",
      "loss: 0.568128  [ 6464/60000]\n",
      "loss: 0.542311  [12864/60000]\n",
      "loss: 0.534134  [19264/60000]\n",
      "loss: 0.499955  [25664/60000]\n",
      "loss: 0.466476  [32064/60000]\n",
      "loss: 0.434517  [38464/60000]\n",
      "loss: 0.661154  [44864/60000]\n",
      "loss: 0.502263  [51264/60000]\n",
      "loss: 0.495200  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.647734 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.594561  [   64/60000]\n",
      "loss: 0.459412  [ 6464/60000]\n",
      "loss: 0.486053  [12864/60000]\n",
      "loss: 0.437160  [19264/60000]\n",
      "loss: 0.439041  [25664/60000]\n",
      "loss: 0.402720  [32064/60000]\n",
      "loss: 0.387644  [38464/60000]\n",
      "loss: 0.641318  [44864/60000]\n",
      "loss: 0.430341  [51264/60000]\n",
      "loss: 0.431807  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.648535 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.596553  [   64/60000]\n",
      "loss: 0.400321  [ 6464/60000]\n",
      "loss: 0.376144  [12864/60000]\n",
      "loss: 0.380745  [19264/60000]\n",
      "loss: 0.399054  [25664/60000]\n",
      "loss: 0.388067  [32064/60000]\n",
      "loss: 0.375745  [38464/60000]\n",
      "loss: 0.561548  [44864/60000]\n",
      "loss: 0.442321  [51264/60000]\n",
      "loss: 0.408213  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.531358 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.408126  [   64/60000]\n",
      "loss: 0.395256  [ 6464/60000]\n",
      "loss: 0.295420  [12864/60000]\n",
      "loss: 0.360987  [19264/60000]\n",
      "loss: 0.326731  [25664/60000]\n",
      "loss: 0.364601  [32064/60000]\n",
      "loss: 0.423588  [38464/60000]\n",
      "loss: 0.529909  [44864/60000]\n",
      "loss: 0.388272  [51264/60000]\n",
      "loss: 0.366853  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.481393 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.317318  [   64/60000]\n",
      "loss: 0.291484  [ 6464/60000]\n",
      "loss: 0.256798  [12864/60000]\n",
      "loss: 0.322517  [19264/60000]\n",
      "loss: 0.374034  [25664/60000]\n",
      "loss: 0.345489  [32064/60000]\n",
      "loss: 0.286047  [38464/60000]\n",
      "loss: 0.430779  [44864/60000]\n",
      "loss: 0.421097  [51264/60000]\n",
      "loss: 0.359465  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.425202 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.284581  [   64/60000]\n",
      "loss: 0.301221  [ 6464/60000]\n",
      "loss: 0.220263  [12864/60000]\n",
      "loss: 0.305517  [19264/60000]\n",
      "loss: 0.346638  [25664/60000]\n",
      "loss: 0.348814  [32064/60000]\n",
      "loss: 0.283114  [38464/60000]\n",
      "loss: 0.409097  [44864/60000]\n",
      "loss: 0.364752  [51264/60000]\n",
      "loss: 0.344901  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.418828 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.286737  [   64/60000]\n",
      "loss: 0.281907  [ 6464/60000]\n",
      "loss: 0.173385  [12864/60000]\n",
      "loss: 0.299205  [19264/60000]\n",
      "loss: 0.329854  [25664/60000]\n",
      "loss: 0.341799  [32064/60000]\n",
      "loss: 0.326552  [38464/60000]\n",
      "loss: 0.357474  [44864/60000]\n",
      "loss: 0.334253  [51264/60000]\n",
      "loss: 0.348582  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.383347 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.201455  [   64/60000]\n",
      "loss: 0.273741  [ 6464/60000]\n",
      "loss: 0.182188  [12864/60000]\n",
      "loss: 0.297079  [19264/60000]\n",
      "loss: 0.371574  [25664/60000]\n",
      "loss: 0.315611  [32064/60000]\n",
      "loss: 0.239338  [38464/60000]\n",
      "loss: 0.448387  [44864/60000]\n",
      "loss: 0.311363  [51264/60000]\n",
      "loss: 0.751581  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.432124 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.283527  [   64/60000]\n",
      "loss: 0.294045  [ 6464/60000]\n",
      "loss: 0.209981  [12864/60000]\n",
      "loss: 0.274586  [19264/60000]\n",
      "loss: 0.323867  [25664/60000]\n",
      "loss: 0.276382  [32064/60000]\n",
      "loss: 0.222390  [38464/60000]\n",
      "loss: 0.342075  [44864/60000]\n",
      "loss: 0.303468  [51264/60000]\n",
      "loss: 0.320005  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.365186 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.229966  [   64/60000]\n",
      "loss: 0.301725  [ 6464/60000]\n",
      "loss: 0.178324  [12864/60000]\n",
      "loss: 0.263369  [19264/60000]\n",
      "loss: 0.299182  [25664/60000]\n",
      "loss: 0.269784  [32064/60000]\n",
      "loss: 0.199231  [38464/60000]\n",
      "loss: 0.332486  [44864/60000]\n",
      "loss: 0.309891  [51264/60000]\n",
      "loss: 0.297132  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.361377 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.164281  [   64/60000]\n",
      "loss: 0.262969  [ 6464/60000]\n",
      "loss: 0.208745  [12864/60000]\n",
      "loss: 0.248267  [19264/60000]\n",
      "loss: 0.274312  [25664/60000]\n",
      "loss: 0.279167  [32064/60000]\n",
      "loss: 0.254161  [38464/60000]\n",
      "loss: 0.320592  [44864/60000]\n",
      "loss: 0.258835  [51264/60000]\n",
      "loss: 0.284612  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.397584 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.246270  [   64/60000]\n",
      "loss: 0.282069  [ 6464/60000]\n",
      "loss: 0.136478  [12864/60000]\n",
      "loss: 0.229531  [19264/60000]\n",
      "loss: 0.276383  [25664/60000]\n",
      "loss: 0.245126  [32064/60000]\n",
      "loss: 0.206201  [38464/60000]\n",
      "loss: 0.268712  [44864/60000]\n",
      "loss: 0.268943  [51264/60000]\n",
      "loss: 0.260943  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.359634 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.143280  [   64/60000]\n",
      "loss: 0.303154  [ 6464/60000]\n",
      "loss: 0.169880  [12864/60000]\n",
      "loss: 0.207951  [19264/60000]\n",
      "loss: 0.271212  [25664/60000]\n",
      "loss: 0.227992  [32064/60000]\n",
      "loss: 0.157956  [38464/60000]\n",
      "loss: 0.259836  [44864/60000]\n",
      "loss: 0.250034  [51264/60000]\n",
      "loss: 0.230707  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.374694 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.152404  [   64/60000]\n",
      "loss: 0.259421  [ 6464/60000]\n",
      "loss: 0.138189  [12864/60000]\n",
      "loss: 0.152553  [19264/60000]\n",
      "loss: 0.265323  [25664/60000]\n",
      "loss: 0.296734  [32064/60000]\n",
      "loss: 0.165805  [38464/60000]\n",
      "loss: 0.225298  [44864/60000]\n",
      "loss: 0.302996  [51264/60000]\n",
      "loss: 0.251230  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.394618 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.169082  [   64/60000]\n",
      "loss: 0.249202  [ 6464/60000]\n",
      "loss: 0.149029  [12864/60000]\n",
      "loss: 0.179203  [19264/60000]\n",
      "loss: 0.250534  [25664/60000]\n",
      "loss: 0.250283  [32064/60000]\n",
      "loss: 0.194443  [38464/60000]\n",
      "loss: 0.211417  [44864/60000]\n",
      "loss: 0.257564  [51264/60000]\n",
      "loss: 0.251542  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.376716 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.177483  [   64/60000]\n",
      "loss: 0.218280  [ 6464/60000]\n",
      "loss: 0.106662  [12864/60000]\n",
      "loss: 0.177693  [19264/60000]\n",
      "loss: 0.358345  [25664/60000]\n",
      "loss: 0.247783  [32064/60000]\n",
      "loss: 0.164911  [38464/60000]\n",
      "loss: 0.286748  [44864/60000]\n",
      "loss: 0.495366  [51264/60000]\n",
      "loss: 0.290564  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.355229 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.129398  [   64/60000]\n",
      "loss: 0.206767  [ 6464/60000]\n",
      "loss: 0.133283  [12864/60000]\n",
      "loss: 0.162046  [19264/60000]\n",
      "loss: 0.299855  [25664/60000]\n",
      "loss: 0.234358  [32064/60000]\n",
      "loss: 0.175701  [38464/60000]\n",
      "loss: 0.216477  [44864/60000]\n",
      "loss: 0.253896  [51264/60000]\n",
      "loss: 0.257748  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.387436 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.149787  [   64/60000]\n",
      "loss: 0.202079  [ 6464/60000]\n",
      "loss: 0.129687  [12864/60000]\n",
      "loss: 0.133374  [19264/60000]\n",
      "loss: 0.253887  [25664/60000]\n",
      "loss: 0.231933  [32064/60000]\n",
      "loss: 0.371138  [38464/60000]\n",
      "loss: 0.221451  [44864/60000]\n",
      "loss: 0.228578  [51264/60000]\n",
      "loss: 0.239464  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.355733 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.129739  [   64/60000]\n",
      "loss: 0.190160  [ 6464/60000]\n",
      "loss: 0.091827  [12864/60000]\n",
      "loss: 0.128201  [19264/60000]\n",
      "loss: 0.230815  [25664/60000]\n",
      "loss: 0.201409  [32064/60000]\n",
      "loss: 0.202797  [38464/60000]\n",
      "loss: 0.190430  [44864/60000]\n",
      "loss: 0.224317  [51264/60000]\n",
      "loss: 0.256539  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.372178 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.139345  [   64/60000]\n",
      "loss: 0.176118  [ 6464/60000]\n",
      "loss: 0.099153  [12864/60000]\n",
      "loss: 0.210187  [19264/60000]\n",
      "loss: 0.228839  [25664/60000]\n",
      "loss: 0.203083  [32064/60000]\n",
      "loss: 0.179821  [38464/60000]\n",
      "loss: 0.226288  [44864/60000]\n",
      "loss: 0.199491  [51264/60000]\n",
      "loss: 0.211610  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.353664 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.150326  [   64/60000]\n",
      "loss: 0.206994  [ 6464/60000]\n",
      "loss: 0.138102  [12864/60000]\n",
      "loss: 0.168507  [19264/60000]\n",
      "loss: 0.205355  [25664/60000]\n",
      "loss: 0.234583  [32064/60000]\n",
      "loss: 0.248737  [38464/60000]\n",
      "loss: 0.218916  [44864/60000]\n",
      "loss: 0.226898  [51264/60000]\n",
      "loss: 0.235652  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.431350 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.208426  [   64/60000]\n",
      "loss: 0.207838  [ 6464/60000]\n",
      "loss: 0.080268  [12864/60000]\n",
      "loss: 0.141576  [19264/60000]\n",
      "loss: 0.247215  [25664/60000]\n",
      "loss: 0.175024  [32064/60000]\n",
      "loss: 0.272502  [38464/60000]\n",
      "loss: 0.169915  [44864/60000]\n",
      "loss: 0.233222  [51264/60000]\n",
      "loss: 0.198487  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.356705 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.132804  [   64/60000]\n",
      "loss: 0.158930  [ 6464/60000]\n",
      "loss: 0.101819  [12864/60000]\n",
      "loss: 0.156893  [19264/60000]\n",
      "loss: 0.214900  [25664/60000]\n",
      "loss: 0.183431  [32064/60000]\n",
      "loss: 0.153112  [38464/60000]\n",
      "loss: 0.154897  [44864/60000]\n",
      "loss: 0.187626  [51264/60000]\n",
      "loss: 0.384700  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.360143 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.113923  [   64/60000]\n",
      "loss: 0.159980  [ 6464/60000]\n",
      "loss: 0.076745  [12864/60000]\n",
      "loss: 0.137443  [19264/60000]\n",
      "loss: 0.177746  [25664/60000]\n",
      "loss: 0.159941  [32064/60000]\n",
      "loss: 0.137518  [38464/60000]\n",
      "loss: 0.166809  [44864/60000]\n",
      "loss: 0.206523  [51264/60000]\n",
      "loss: 0.211281  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.375794 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.139465  [   64/60000]\n",
      "loss: 0.406456  [ 6464/60000]\n",
      "loss: 0.087431  [12864/60000]\n",
      "loss: 0.076335  [19264/60000]\n",
      "loss: 0.201937  [25664/60000]\n",
      "loss: 0.163610  [32064/60000]\n",
      "loss: 0.125809  [38464/60000]\n",
      "loss: 0.156056  [44864/60000]\n",
      "loss: 0.230704  [51264/60000]\n",
      "loss: 0.179960  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.410532 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.158840  [   64/60000]\n",
      "loss: 0.164164  [ 6464/60000]\n",
      "loss: 0.099848  [12864/60000]\n",
      "loss: 0.090202  [19264/60000]\n",
      "loss: 0.230264  [25664/60000]\n",
      "loss: 0.180958  [32064/60000]\n",
      "loss: 0.186225  [38464/60000]\n",
      "loss: 0.148139  [44864/60000]\n",
      "loss: 0.182708  [51264/60000]\n",
      "loss: 0.196899  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.401698 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.113180  [   64/60000]\n",
      "loss: 0.152875  [ 6464/60000]\n",
      "loss: 0.077780  [12864/60000]\n",
      "loss: 0.116494  [19264/60000]\n",
      "loss: 0.140893  [25664/60000]\n",
      "loss: 0.163816  [32064/60000]\n",
      "loss: 0.142423  [38464/60000]\n",
      "loss: 0.161172  [44864/60000]\n",
      "loss: 0.167631  [51264/60000]\n",
      "loss: 0.235772  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.387036 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.124182  [   64/60000]\n",
      "loss: 0.168206  [ 6464/60000]\n",
      "loss: 0.080605  [12864/60000]\n",
      "loss: 0.124357  [19264/60000]\n",
      "loss: 0.128304  [25664/60000]\n",
      "loss: 0.138778  [32064/60000]\n",
      "loss: 0.124741  [38464/60000]\n",
      "loss: 0.259171  [44864/60000]\n",
      "loss: 0.167869  [51264/60000]\n",
      "loss: 0.198053  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.392740 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.137369  [   64/60000]\n",
      "loss: 0.233448  [ 6464/60000]\n",
      "loss: 0.087919  [12864/60000]\n",
      "loss: 0.143070  [19264/60000]\n",
      "loss: 0.334295  [25664/60000]\n",
      "loss: 0.159014  [32064/60000]\n",
      "loss: 0.104319  [38464/60000]\n",
      "loss: 0.145198  [44864/60000]\n",
      "loss: 0.180852  [51264/60000]\n",
      "loss: 0.150698  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.395430 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.095627  [   64/60000]\n",
      "loss: 0.085889  [ 6464/60000]\n",
      "loss: 0.074845  [12864/60000]\n",
      "loss: 0.062587  [19264/60000]\n",
      "loss: 0.171041  [25664/60000]\n",
      "loss: 0.162104  [32064/60000]\n",
      "loss: 0.122231  [38464/60000]\n",
      "loss: 0.115251  [44864/60000]\n",
      "loss: 0.218241  [51264/60000]\n",
      "loss: 0.227492  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.428274 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.145453  [   64/60000]\n",
      "loss: 0.103533  [ 6464/60000]\n",
      "loss: 0.120693  [12864/60000]\n",
      "loss: 0.097314  [19264/60000]\n",
      "loss: 0.197560  [25664/60000]\n",
      "loss: 0.160660  [32064/60000]\n",
      "loss: 0.172418  [38464/60000]\n",
      "loss: 0.194867  [44864/60000]\n",
      "loss: 0.279669  [51264/60000]\n",
      "loss: 0.188003  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.397672 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.083320  [   64/60000]\n",
      "loss: 0.130590  [ 6464/60000]\n",
      "loss: 0.098103  [12864/60000]\n",
      "loss: 0.077680  [19264/60000]\n",
      "loss: 0.145222  [25664/60000]\n",
      "loss: 0.134919  [32064/60000]\n",
      "loss: 0.079392  [38464/60000]\n",
      "loss: 0.135255  [44864/60000]\n",
      "loss: 0.107953  [51264/60000]\n",
      "loss: 0.165867  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.405954 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.169177  [   64/60000]\n",
      "loss: 0.155113  [ 6464/60000]\n",
      "loss: 0.110689  [12864/60000]\n",
      "loss: 0.087929  [19264/60000]\n",
      "loss: 0.153976  [25664/60000]\n",
      "loss: 0.148247  [32064/60000]\n",
      "loss: 0.149393  [38464/60000]\n",
      "loss: 0.159873  [44864/60000]\n",
      "loss: 0.169387  [51264/60000]\n",
      "loss: 0.175958  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.420079 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.118025  [   64/60000]\n",
      "loss: 0.110609  [ 6464/60000]\n",
      "loss: 0.096432  [12864/60000]\n",
      "loss: 0.049824  [19264/60000]\n",
      "loss: 0.200780  [25664/60000]\n",
      "loss: 0.126718  [32064/60000]\n",
      "loss: 0.160627  [38464/60000]\n",
      "loss: 0.088568  [44864/60000]\n",
      "loss: 0.196992  [51264/60000]\n",
      "loss: 0.201196  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.454598 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.123222  [   64/60000]\n",
      "loss: 0.124307  [ 6464/60000]\n",
      "loss: 0.056881  [12864/60000]\n",
      "loss: 0.074856  [19264/60000]\n",
      "loss: 0.111688  [25664/60000]\n",
      "loss: 0.129512  [32064/60000]\n",
      "loss: 0.137734  [38464/60000]\n",
      "loss: 0.108629  [44864/60000]\n",
      "loss: 0.176525  [51264/60000]\n",
      "loss: 0.170656  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 2.189904 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.119995  [   64/60000]\n",
      "loss: 0.090319  [ 6464/60000]\n",
      "loss: 0.054586  [12864/60000]\n",
      "loss: 0.078709  [19264/60000]\n",
      "loss: 0.078905  [25664/60000]\n",
      "loss: 0.154901  [32064/60000]\n",
      "loss: 0.125087  [38464/60000]\n",
      "loss: 0.084620  [44864/60000]\n",
      "loss: 0.213847  [51264/60000]\n",
      "loss: 0.276008  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.444178 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.156363  [   64/60000]\n",
      "loss: 0.108157  [ 6464/60000]\n",
      "loss: 0.089595  [12864/60000]\n",
      "loss: 0.141123  [19264/60000]\n",
      "loss: 0.124946  [25664/60000]\n",
      "loss: 0.107088  [32064/60000]\n",
      "loss: 0.094752  [38464/60000]\n",
      "loss: 0.131760  [44864/60000]\n",
      "loss: 0.200890  [51264/60000]\n",
      "loss: 0.151021  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.429545 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.093100  [   64/60000]\n",
      "loss: 0.116000  [ 6464/60000]\n",
      "loss: 0.076164  [12864/60000]\n",
      "loss: 0.111430  [19264/60000]\n",
      "loss: 0.110690  [25664/60000]\n",
      "loss: 0.164308  [32064/60000]\n",
      "loss: 0.230589  [38464/60000]\n",
      "loss: 0.092736  [44864/60000]\n",
      "loss: 0.157058  [51264/60000]\n",
      "loss: 0.123458  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.442060 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.082115  [   64/60000]\n",
      "loss: 0.097536  [ 6464/60000]\n",
      "loss: 0.084808  [12864/60000]\n",
      "loss: 0.094417  [19264/60000]\n",
      "loss: 0.180163  [25664/60000]\n",
      "loss: 0.086509  [32064/60000]\n",
      "loss: 0.074682  [38464/60000]\n",
      "loss: 0.081040  [44864/60000]\n",
      "loss: 0.188326  [51264/60000]\n",
      "loss: 0.134882  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.514649 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.146441  [   64/60000]\n",
      "loss: 0.093509  [ 6464/60000]\n",
      "loss: 0.119793  [12864/60000]\n",
      "loss: 0.029804  [19264/60000]\n",
      "loss: 0.210744  [25664/60000]\n",
      "loss: 0.131857  [32064/60000]\n",
      "loss: 0.070192  [38464/60000]\n",
      "loss: 0.098979  [44864/60000]\n",
      "loss: 0.144504  [51264/60000]\n",
      "loss: 0.143754  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.404340 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.105916  [   64/60000]\n",
      "loss: 0.095377  [ 6464/60000]\n",
      "loss: 0.045080  [12864/60000]\n",
      "loss: 0.060555  [19264/60000]\n",
      "loss: 0.084238  [25664/60000]\n",
      "loss: 0.114610  [32064/60000]\n",
      "loss: 0.052660  [38464/60000]\n",
      "loss: 0.106104  [44864/60000]\n",
      "loss: 0.113495  [51264/60000]\n",
      "loss: 0.105347  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.439794 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.100279  [   64/60000]\n",
      "loss: 0.023247  [ 6464/60000]\n",
      "loss: 0.071135  [12864/60000]\n",
      "loss: 0.051711  [19264/60000]\n",
      "loss: 0.106058  [25664/60000]\n",
      "loss: 0.067565  [32064/60000]\n",
      "loss: 0.058005  [38464/60000]\n",
      "loss: 0.091845  [44864/60000]\n",
      "loss: 0.055187  [51264/60000]\n",
      "loss: 0.124858  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.496098 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.123678  [   64/60000]\n",
      "loss: 0.047068  [ 6464/60000]\n",
      "loss: 0.081809  [12864/60000]\n",
      "loss: 0.038489  [19264/60000]\n",
      "loss: 0.126161  [25664/60000]\n",
      "loss: 0.121933  [32064/60000]\n",
      "loss: 0.085073  [38464/60000]\n",
      "loss: 0.091961  [44864/60000]\n",
      "loss: 0.076116  [51264/60000]\n",
      "loss: 0.125757  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.437237 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.097330  [   64/60000]\n",
      "loss: 0.276710  [ 6464/60000]\n",
      "loss: 0.080205  [12864/60000]\n",
      "loss: 0.041224  [19264/60000]\n",
      "loss: 0.034080  [25664/60000]\n",
      "loss: 0.195562  [32064/60000]\n",
      "loss: 0.098053  [38464/60000]\n",
      "loss: 0.083463  [44864/60000]\n",
      "loss: 0.071340  [51264/60000]\n",
      "loss: 0.090956  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.466581 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.099881  [   64/60000]\n",
      "loss: 0.063974  [ 6464/60000]\n",
      "loss: 0.051655  [12864/60000]\n",
      "loss: 0.068068  [19264/60000]\n",
      "loss: 0.069287  [25664/60000]\n",
      "loss: 0.068660  [32064/60000]\n",
      "loss: 0.113069  [38464/60000]\n",
      "loss: 0.080918  [44864/60000]\n",
      "loss: 0.041339  [51264/60000]\n",
      "loss: 0.073456  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.484738 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.099988  [   64/60000]\n",
      "loss: 0.066593  [ 6464/60000]\n",
      "loss: 0.063869  [12864/60000]\n",
      "loss: 0.032495  [19264/60000]\n",
      "loss: 0.141768  [25664/60000]\n",
      "loss: 0.053609  [32064/60000]\n",
      "loss: 0.124052  [38464/60000]\n",
      "loss: 0.129525  [44864/60000]\n",
      "loss: 0.096698  [51264/60000]\n",
      "loss: 0.061788  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.435439 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, deep_model, loss_fn, deep_optimizer)\n",
    "    test(test_dataloader, deep_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "81e51da8-8f2b-4a7c-8c85-c67285e0f12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeuralNetwork(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class ConvNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(128 * 3 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "conv_model = ConvNeuralNetwork().to(device)\n",
    "print(conv_model)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "conv_optimizer = torch.optim.SGD(conv_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8eb0ce5a-48b6-4787-b178-804d25032308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.383144  [   64/60000]\n",
      "loss: 0.374868  [ 6464/60000]\n",
      "loss: 0.255228  [12864/60000]\n",
      "loss: 0.480184  [19264/60000]\n",
      "loss: 0.435587  [25664/60000]\n",
      "loss: 0.496247  [32064/60000]\n",
      "loss: 0.464977  [38464/60000]\n",
      "loss: 0.477544  [44864/60000]\n",
      "loss: 0.586155  [51264/60000]\n",
      "loss: 0.455852  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.457844 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.380831  [   64/60000]\n",
      "loss: 0.372115  [ 6464/60000]\n",
      "loss: 0.252053  [12864/60000]\n",
      "loss: 0.477393  [19264/60000]\n",
      "loss: 0.431687  [25664/60000]\n",
      "loss: 0.492856  [32064/60000]\n",
      "loss: 0.462793  [38464/60000]\n",
      "loss: 0.475945  [44864/60000]\n",
      "loss: 0.584754  [51264/60000]\n",
      "loss: 0.452186  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.454768 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.378951  [   64/60000]\n",
      "loss: 0.369502  [ 6464/60000]\n",
      "loss: 0.249000  [12864/60000]\n",
      "loss: 0.475023  [19264/60000]\n",
      "loss: 0.428684  [25664/60000]\n",
      "loss: 0.489106  [32064/60000]\n",
      "loss: 0.460967  [38464/60000]\n",
      "loss: 0.474160  [44864/60000]\n",
      "loss: 0.583252  [51264/60000]\n",
      "loss: 0.449069  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.452390 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.377173  [   64/60000]\n",
      "loss: 0.365934  [ 6464/60000]\n",
      "loss: 0.245596  [12864/60000]\n",
      "loss: 0.473204  [19264/60000]\n",
      "loss: 0.424479  [25664/60000]\n",
      "loss: 0.486146  [32064/60000]\n",
      "loss: 0.458786  [38464/60000]\n",
      "loss: 0.472054  [44864/60000]\n",
      "loss: 0.581753  [51264/60000]\n",
      "loss: 0.446502  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.449587 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.374092  [   64/60000]\n",
      "loss: 0.362647  [ 6464/60000]\n",
      "loss: 0.243258  [12864/60000]\n",
      "loss: 0.470586  [19264/60000]\n",
      "loss: 0.421381  [25664/60000]\n",
      "loss: 0.480849  [32064/60000]\n",
      "loss: 0.457126  [38464/60000]\n",
      "loss: 0.471770  [44864/60000]\n",
      "loss: 0.579893  [51264/60000]\n",
      "loss: 0.444378  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.446930 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.371448  [   64/60000]\n",
      "loss: 0.360256  [ 6464/60000]\n",
      "loss: 0.239760  [12864/60000]\n",
      "loss: 0.468569  [19264/60000]\n",
      "loss: 0.417802  [25664/60000]\n",
      "loss: 0.478157  [32064/60000]\n",
      "loss: 0.455166  [38464/60000]\n",
      "loss: 0.468721  [44864/60000]\n",
      "loss: 0.579363  [51264/60000]\n",
      "loss: 0.441696  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.443973 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.368100  [   64/60000]\n",
      "loss: 0.357684  [ 6464/60000]\n",
      "loss: 0.237049  [12864/60000]\n",
      "loss: 0.465825  [19264/60000]\n",
      "loss: 0.414420  [25664/60000]\n",
      "loss: 0.475015  [32064/60000]\n",
      "loss: 0.453738  [38464/60000]\n",
      "loss: 0.468139  [44864/60000]\n",
      "loss: 0.578117  [51264/60000]\n",
      "loss: 0.440230  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.441268 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.365436  [   64/60000]\n",
      "loss: 0.354898  [ 6464/60000]\n",
      "loss: 0.234482  [12864/60000]\n",
      "loss: 0.464395  [19264/60000]\n",
      "loss: 0.410636  [25664/60000]\n",
      "loss: 0.472988  [32064/60000]\n",
      "loss: 0.452447  [38464/60000]\n",
      "loss: 0.465696  [44864/60000]\n",
      "loss: 0.575794  [51264/60000]\n",
      "loss: 0.437209  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.438467 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.362960  [   64/60000]\n",
      "loss: 0.351986  [ 6464/60000]\n",
      "loss: 0.232345  [12864/60000]\n",
      "loss: 0.461886  [19264/60000]\n",
      "loss: 0.407963  [25664/60000]\n",
      "loss: 0.469699  [32064/60000]\n",
      "loss: 0.450596  [38464/60000]\n",
      "loss: 0.464939  [44864/60000]\n",
      "loss: 0.574342  [51264/60000]\n",
      "loss: 0.435189  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.436463 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.360937  [   64/60000]\n",
      "loss: 0.350045  [ 6464/60000]\n",
      "loss: 0.230824  [12864/60000]\n",
      "loss: 0.460776  [19264/60000]\n",
      "loss: 0.405489  [25664/60000]\n",
      "loss: 0.468155  [32064/60000]\n",
      "loss: 0.447567  [38464/60000]\n",
      "loss: 0.464408  [44864/60000]\n",
      "loss: 0.571333  [51264/60000]\n",
      "loss: 0.434016  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.434203 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.358566  [   64/60000]\n",
      "loss: 0.347838  [ 6464/60000]\n",
      "loss: 0.228040  [12864/60000]\n",
      "loss: 0.458375  [19264/60000]\n",
      "loss: 0.402308  [25664/60000]\n",
      "loss: 0.464850  [32064/60000]\n",
      "loss: 0.445253  [38464/60000]\n",
      "loss: 0.462591  [44864/60000]\n",
      "loss: 0.570187  [51264/60000]\n",
      "loss: 0.433190  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.431920 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.357263  [   64/60000]\n",
      "loss: 0.346480  [ 6464/60000]\n",
      "loss: 0.226063  [12864/60000]\n",
      "loss: 0.457407  [19264/60000]\n",
      "loss: 0.399449  [25664/60000]\n",
      "loss: 0.463162  [32064/60000]\n",
      "loss: 0.443716  [38464/60000]\n",
      "loss: 0.460680  [44864/60000]\n",
      "loss: 0.567109  [51264/60000]\n",
      "loss: 0.431863  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.429297 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.354229  [   64/60000]\n",
      "loss: 0.344980  [ 6464/60000]\n",
      "loss: 0.224125  [12864/60000]\n",
      "loss: 0.455146  [19264/60000]\n",
      "loss: 0.396208  [25664/60000]\n",
      "loss: 0.459746  [32064/60000]\n",
      "loss: 0.442291  [38464/60000]\n",
      "loss: 0.458543  [44864/60000]\n",
      "loss: 0.565974  [51264/60000]\n",
      "loss: 0.429071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.427662 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.353221  [   64/60000]\n",
      "loss: 0.342645  [ 6464/60000]\n",
      "loss: 0.221545  [12864/60000]\n",
      "loss: 0.453030  [19264/60000]\n",
      "loss: 0.392380  [25664/60000]\n",
      "loss: 0.456896  [32064/60000]\n",
      "loss: 0.439091  [38464/60000]\n",
      "loss: 0.456296  [44864/60000]\n",
      "loss: 0.563601  [51264/60000]\n",
      "loss: 0.428261  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.424748 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.349407  [   64/60000]\n",
      "loss: 0.340698  [ 6464/60000]\n",
      "loss: 0.219668  [12864/60000]\n",
      "loss: 0.451222  [19264/60000]\n",
      "loss: 0.387786  [25664/60000]\n",
      "loss: 0.455391  [32064/60000]\n",
      "loss: 0.437760  [38464/60000]\n",
      "loss: 0.453445  [44864/60000]\n",
      "loss: 0.561245  [51264/60000]\n",
      "loss: 0.426372  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.422934 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.348322  [   64/60000]\n",
      "loss: 0.338625  [ 6464/60000]\n",
      "loss: 0.217304  [12864/60000]\n",
      "loss: 0.449285  [19264/60000]\n",
      "loss: 0.383702  [25664/60000]\n",
      "loss: 0.451499  [32064/60000]\n",
      "loss: 0.435589  [38464/60000]\n",
      "loss: 0.451966  [44864/60000]\n",
      "loss: 0.559800  [51264/60000]\n",
      "loss: 0.423911  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.420025 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.345607  [   64/60000]\n",
      "loss: 0.337782  [ 6464/60000]\n",
      "loss: 0.215006  [12864/60000]\n",
      "loss: 0.447491  [19264/60000]\n",
      "loss: 0.380990  [25664/60000]\n",
      "loss: 0.450168  [32064/60000]\n",
      "loss: 0.433622  [38464/60000]\n",
      "loss: 0.449567  [44864/60000]\n",
      "loss: 0.557428  [51264/60000]\n",
      "loss: 0.421905  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.418775 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.345361  [   64/60000]\n",
      "loss: 0.335328  [ 6464/60000]\n",
      "loss: 0.213321  [12864/60000]\n",
      "loss: 0.445828  [19264/60000]\n",
      "loss: 0.377368  [25664/60000]\n",
      "loss: 0.447469  [32064/60000]\n",
      "loss: 0.430971  [38464/60000]\n",
      "loss: 0.449533  [44864/60000]\n",
      "loss: 0.554559  [51264/60000]\n",
      "loss: 0.419010  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.416177 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.342844  [   64/60000]\n",
      "loss: 0.333323  [ 6464/60000]\n",
      "loss: 0.211372  [12864/60000]\n",
      "loss: 0.444106  [19264/60000]\n",
      "loss: 0.374594  [25664/60000]\n",
      "loss: 0.445257  [32064/60000]\n",
      "loss: 0.429406  [38464/60000]\n",
      "loss: 0.448673  [44864/60000]\n",
      "loss: 0.552568  [51264/60000]\n",
      "loss: 0.416328  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.413850 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.340856  [   64/60000]\n",
      "loss: 0.331744  [ 6464/60000]\n",
      "loss: 0.209177  [12864/60000]\n",
      "loss: 0.442595  [19264/60000]\n",
      "loss: 0.371887  [25664/60000]\n",
      "loss: 0.442654  [32064/60000]\n",
      "loss: 0.426833  [38464/60000]\n",
      "loss: 0.445330  [44864/60000]\n",
      "loss: 0.551498  [51264/60000]\n",
      "loss: 0.415438  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.411870 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.339470  [   64/60000]\n",
      "loss: 0.329733  [ 6464/60000]\n",
      "loss: 0.207811  [12864/60000]\n",
      "loss: 0.440014  [19264/60000]\n",
      "loss: 0.369069  [25664/60000]\n",
      "loss: 0.441286  [32064/60000]\n",
      "loss: 0.424741  [38464/60000]\n",
      "loss: 0.445020  [44864/60000]\n",
      "loss: 0.551123  [51264/60000]\n",
      "loss: 0.414119  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.412570 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.341190  [   64/60000]\n",
      "loss: 0.329155  [ 6464/60000]\n",
      "loss: 0.205946  [12864/60000]\n",
      "loss: 0.439333  [19264/60000]\n",
      "loss: 0.366134  [25664/60000]\n",
      "loss: 0.438838  [32064/60000]\n",
      "loss: 0.422270  [38464/60000]\n",
      "loss: 0.444574  [44864/60000]\n",
      "loss: 0.549390  [51264/60000]\n",
      "loss: 0.412697  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.411118 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.340488  [   64/60000]\n",
      "loss: 0.326333  [ 6464/60000]\n",
      "loss: 0.203694  [12864/60000]\n",
      "loss: 0.437447  [19264/60000]\n",
      "loss: 0.364137  [25664/60000]\n",
      "loss: 0.437524  [32064/60000]\n",
      "loss: 0.420074  [38464/60000]\n",
      "loss: 0.443072  [44864/60000]\n",
      "loss: 0.546145  [51264/60000]\n",
      "loss: 0.412323  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.408163 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.337023  [   64/60000]\n",
      "loss: 0.326008  [ 6464/60000]\n",
      "loss: 0.202156  [12864/60000]\n",
      "loss: 0.435746  [19264/60000]\n",
      "loss: 0.361642  [25664/60000]\n",
      "loss: 0.434094  [32064/60000]\n",
      "loss: 0.418000  [38464/60000]\n",
      "loss: 0.441936  [44864/60000]\n",
      "loss: 0.544246  [51264/60000]\n",
      "loss: 0.410700  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.406757 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.335961  [   64/60000]\n",
      "loss: 0.324516  [ 6464/60000]\n",
      "loss: 0.200017  [12864/60000]\n",
      "loss: 0.433249  [19264/60000]\n",
      "loss: 0.358715  [25664/60000]\n",
      "loss: 0.433043  [32064/60000]\n",
      "loss: 0.416102  [38464/60000]\n",
      "loss: 0.440250  [44864/60000]\n",
      "loss: 0.540963  [51264/60000]\n",
      "loss: 0.408704  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.404739 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.334320  [   64/60000]\n",
      "loss: 0.322651  [ 6464/60000]\n",
      "loss: 0.198406  [12864/60000]\n",
      "loss: 0.431341  [19264/60000]\n",
      "loss: 0.355840  [25664/60000]\n",
      "loss: 0.430440  [32064/60000]\n",
      "loss: 0.413139  [38464/60000]\n",
      "loss: 0.440076  [44864/60000]\n",
      "loss: 0.539203  [51264/60000]\n",
      "loss: 0.407517  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.403092 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.332641  [   64/60000]\n",
      "loss: 0.321315  [ 6464/60000]\n",
      "loss: 0.197228  [12864/60000]\n",
      "loss: 0.429886  [19264/60000]\n",
      "loss: 0.353181  [25664/60000]\n",
      "loss: 0.429926  [32064/60000]\n",
      "loss: 0.411127  [38464/60000]\n",
      "loss: 0.438742  [44864/60000]\n",
      "loss: 0.536448  [51264/60000]\n",
      "loss: 0.406031  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.401423 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.331611  [   64/60000]\n",
      "loss: 0.319644  [ 6464/60000]\n",
      "loss: 0.195998  [12864/60000]\n",
      "loss: 0.428773  [19264/60000]\n",
      "loss: 0.350319  [25664/60000]\n",
      "loss: 0.427279  [32064/60000]\n",
      "loss: 0.408911  [38464/60000]\n",
      "loss: 0.438183  [44864/60000]\n",
      "loss: 0.534219  [51264/60000]\n",
      "loss: 0.404032  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.400026 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.330873  [   64/60000]\n",
      "loss: 0.319060  [ 6464/60000]\n",
      "loss: 0.194579  [12864/60000]\n",
      "loss: 0.426766  [19264/60000]\n",
      "loss: 0.348299  [25664/60000]\n",
      "loss: 0.425779  [32064/60000]\n",
      "loss: 0.407473  [38464/60000]\n",
      "loss: 0.436111  [44864/60000]\n",
      "loss: 0.531976  [51264/60000]\n",
      "loss: 0.403517  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.397979 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.329444  [   64/60000]\n",
      "loss: 0.317806  [ 6464/60000]\n",
      "loss: 0.192227  [12864/60000]\n",
      "loss: 0.425670  [19264/60000]\n",
      "loss: 0.346039  [25664/60000]\n",
      "loss: 0.423471  [32064/60000]\n",
      "loss: 0.405482  [38464/60000]\n",
      "loss: 0.435485  [44864/60000]\n",
      "loss: 0.529316  [51264/60000]\n",
      "loss: 0.401725  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.396043 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.327316  [   64/60000]\n",
      "loss: 0.316266  [ 6464/60000]\n",
      "loss: 0.190716  [12864/60000]\n",
      "loss: 0.424593  [19264/60000]\n",
      "loss: 0.343771  [25664/60000]\n",
      "loss: 0.422742  [32064/60000]\n",
      "loss: 0.403154  [38464/60000]\n",
      "loss: 0.433950  [44864/60000]\n",
      "loss: 0.527467  [51264/60000]\n",
      "loss: 0.401282  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.394169 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.325570  [   64/60000]\n",
      "loss: 0.314574  [ 6464/60000]\n",
      "loss: 0.190451  [12864/60000]\n",
      "loss: 0.422453  [19264/60000]\n",
      "loss: 0.341642  [25664/60000]\n",
      "loss: 0.422390  [32064/60000]\n",
      "loss: 0.400323  [38464/60000]\n",
      "loss: 0.433885  [44864/60000]\n",
      "loss: 0.525536  [51264/60000]\n",
      "loss: 0.400311  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.392235 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.324762  [   64/60000]\n",
      "loss: 0.313273  [ 6464/60000]\n",
      "loss: 0.189320  [12864/60000]\n",
      "loss: 0.420704  [19264/60000]\n",
      "loss: 0.338264  [25664/60000]\n",
      "loss: 0.419514  [32064/60000]\n",
      "loss: 0.398476  [38464/60000]\n",
      "loss: 0.432434  [44864/60000]\n",
      "loss: 0.525223  [51264/60000]\n",
      "loss: 0.399556  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.390064 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.321457  [   64/60000]\n",
      "loss: 0.311370  [ 6464/60000]\n",
      "loss: 0.188317  [12864/60000]\n",
      "loss: 0.419304  [19264/60000]\n",
      "loss: 0.336030  [25664/60000]\n",
      "loss: 0.418216  [32064/60000]\n",
      "loss: 0.396419  [38464/60000]\n",
      "loss: 0.432011  [44864/60000]\n",
      "loss: 0.523133  [51264/60000]\n",
      "loss: 0.399975  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.388103 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.319764  [   64/60000]\n",
      "loss: 0.309742  [ 6464/60000]\n",
      "loss: 0.186695  [12864/60000]\n",
      "loss: 0.417565  [19264/60000]\n",
      "loss: 0.333689  [25664/60000]\n",
      "loss: 0.416796  [32064/60000]\n",
      "loss: 0.394038  [38464/60000]\n",
      "loss: 0.430983  [44864/60000]\n",
      "loss: 0.521165  [51264/60000]\n",
      "loss: 0.397584  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.386119 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.317295  [   64/60000]\n",
      "loss: 0.308935  [ 6464/60000]\n",
      "loss: 0.185732  [12864/60000]\n",
      "loss: 0.415601  [19264/60000]\n",
      "loss: 0.331505  [25664/60000]\n",
      "loss: 0.415959  [32064/60000]\n",
      "loss: 0.392627  [38464/60000]\n",
      "loss: 0.429670  [44864/60000]\n",
      "loss: 0.519704  [51264/60000]\n",
      "loss: 0.397136  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.384732 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.315758  [   64/60000]\n",
      "loss: 0.306528  [ 6464/60000]\n",
      "loss: 0.184949  [12864/60000]\n",
      "loss: 0.413592  [19264/60000]\n",
      "loss: 0.328884  [25664/60000]\n",
      "loss: 0.414070  [32064/60000]\n",
      "loss: 0.390927  [38464/60000]\n",
      "loss: 0.429486  [44864/60000]\n",
      "loss: 0.517579  [51264/60000]\n",
      "loss: 0.395403  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.383590 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.316444  [   64/60000]\n",
      "loss: 0.306609  [ 6464/60000]\n",
      "loss: 0.184238  [12864/60000]\n",
      "loss: 0.411420  [19264/60000]\n",
      "loss: 0.325974  [25664/60000]\n",
      "loss: 0.413558  [32064/60000]\n",
      "loss: 0.389530  [38464/60000]\n",
      "loss: 0.428646  [44864/60000]\n",
      "loss: 0.515614  [51264/60000]\n",
      "loss: 0.395092  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.380774 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.312122  [   64/60000]\n",
      "loss: 0.304550  [ 6464/60000]\n",
      "loss: 0.182447  [12864/60000]\n",
      "loss: 0.408649  [19264/60000]\n",
      "loss: 0.323607  [25664/60000]\n",
      "loss: 0.411629  [32064/60000]\n",
      "loss: 0.387789  [38464/60000]\n",
      "loss: 0.427915  [44864/60000]\n",
      "loss: 0.513939  [51264/60000]\n",
      "loss: 0.393837  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.379589 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.310864  [   64/60000]\n",
      "loss: 0.303728  [ 6464/60000]\n",
      "loss: 0.181760  [12864/60000]\n",
      "loss: 0.406757  [19264/60000]\n",
      "loss: 0.321694  [25664/60000]\n",
      "loss: 0.410019  [32064/60000]\n",
      "loss: 0.385765  [38464/60000]\n",
      "loss: 0.426261  [44864/60000]\n",
      "loss: 0.513287  [51264/60000]\n",
      "loss: 0.392856  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.377908 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.308927  [   64/60000]\n",
      "loss: 0.302400  [ 6464/60000]\n",
      "loss: 0.180431  [12864/60000]\n",
      "loss: 0.404496  [19264/60000]\n",
      "loss: 0.319835  [25664/60000]\n",
      "loss: 0.408149  [32064/60000]\n",
      "loss: 0.383041  [38464/60000]\n",
      "loss: 0.426032  [44864/60000]\n",
      "loss: 0.511080  [51264/60000]\n",
      "loss: 0.391264  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.376311 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.305696  [   64/60000]\n",
      "loss: 0.301059  [ 6464/60000]\n",
      "loss: 0.179182  [12864/60000]\n",
      "loss: 0.402563  [19264/60000]\n",
      "loss: 0.316714  [25664/60000]\n",
      "loss: 0.406330  [32064/60000]\n",
      "loss: 0.382220  [38464/60000]\n",
      "loss: 0.427157  [44864/60000]\n",
      "loss: 0.509879  [51264/60000]\n",
      "loss: 0.390316  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.374867 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.304726  [   64/60000]\n",
      "loss: 0.299634  [ 6464/60000]\n",
      "loss: 0.177330  [12864/60000]\n",
      "loss: 0.401857  [19264/60000]\n",
      "loss: 0.314576  [25664/60000]\n",
      "loss: 0.406459  [32064/60000]\n",
      "loss: 0.379332  [38464/60000]\n",
      "loss: 0.427050  [44864/60000]\n",
      "loss: 0.509431  [51264/60000]\n",
      "loss: 0.389954  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.373185 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.302771  [   64/60000]\n",
      "loss: 0.297866  [ 6464/60000]\n",
      "loss: 0.177023  [12864/60000]\n",
      "loss: 0.399314  [19264/60000]\n",
      "loss: 0.311985  [25664/60000]\n",
      "loss: 0.406531  [32064/60000]\n",
      "loss: 0.378755  [38464/60000]\n",
      "loss: 0.425727  [44864/60000]\n",
      "loss: 0.508306  [51264/60000]\n",
      "loss: 0.388700  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.372559 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.303318  [   64/60000]\n",
      "loss: 0.297007  [ 6464/60000]\n",
      "loss: 0.176322  [12864/60000]\n",
      "loss: 0.397124  [19264/60000]\n",
      "loss: 0.310396  [25664/60000]\n",
      "loss: 0.404533  [32064/60000]\n",
      "loss: 0.376607  [38464/60000]\n",
      "loss: 0.425180  [44864/60000]\n",
      "loss: 0.506815  [51264/60000]\n",
      "loss: 0.390666  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.370754 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.302784  [   64/60000]\n",
      "loss: 0.296077  [ 6464/60000]\n",
      "loss: 0.175494  [12864/60000]\n",
      "loss: 0.395085  [19264/60000]\n",
      "loss: 0.308018  [25664/60000]\n",
      "loss: 0.403960  [32064/60000]\n",
      "loss: 0.374674  [38464/60000]\n",
      "loss: 0.423422  [44864/60000]\n",
      "loss: 0.505610  [51264/60000]\n",
      "loss: 0.389554  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.369688 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.300037  [   64/60000]\n",
      "loss: 0.294485  [ 6464/60000]\n",
      "loss: 0.173987  [12864/60000]\n",
      "loss: 0.392434  [19264/60000]\n",
      "loss: 0.305719  [25664/60000]\n",
      "loss: 0.399720  [32064/60000]\n",
      "loss: 0.374423  [38464/60000]\n",
      "loss: 0.424142  [44864/60000]\n",
      "loss: 0.504830  [51264/60000]\n",
      "loss: 0.387152  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.367768 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.297228  [   64/60000]\n",
      "loss: 0.293375  [ 6464/60000]\n",
      "loss: 0.172270  [12864/60000]\n",
      "loss: 0.390540  [19264/60000]\n",
      "loss: 0.304698  [25664/60000]\n",
      "loss: 0.400666  [32064/60000]\n",
      "loss: 0.372294  [38464/60000]\n",
      "loss: 0.422738  [44864/60000]\n",
      "loss: 0.503723  [51264/60000]\n",
      "loss: 0.387737  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.366082 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.295839  [   64/60000]\n",
      "loss: 0.291917  [ 6464/60000]\n",
      "loss: 0.171422  [12864/60000]\n",
      "loss: 0.388691  [19264/60000]\n",
      "loss: 0.304026  [25664/60000]\n",
      "loss: 0.398309  [32064/60000]\n",
      "loss: 0.370961  [38464/60000]\n",
      "loss: 0.421987  [44864/60000]\n",
      "loss: 0.501827  [51264/60000]\n",
      "loss: 0.386886  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.365358 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.295636  [   64/60000]\n",
      "loss: 0.289516  [ 6464/60000]\n",
      "loss: 0.170536  [12864/60000]\n",
      "loss: 0.386616  [19264/60000]\n",
      "loss: 0.301813  [25664/60000]\n",
      "loss: 0.399150  [32064/60000]\n",
      "loss: 0.368350  [38464/60000]\n",
      "loss: 0.420932  [44864/60000]\n",
      "loss: 0.500438  [51264/60000]\n",
      "loss: 0.386370  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.363842 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, conv_model, loss_fn, conv_optimizer)\n",
    "    test(test_dataloader, conv_model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba040c62-dc48-45b4-8848-887b9592f571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
